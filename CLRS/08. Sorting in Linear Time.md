# 8. Sorting in Linear Time

## ğŸ“‹ Chapter Overview

| Section | Topic         | Key Idea                                |
| ------- | ------------- | --------------------------------------- |
| **8.1** | Lower bounds  | Comparison sorts need Î©(n log n)        |
| **8.2** | Counting sort | O(n + k) for small integer range        |
| **8.3** | Radix sort    | Digit-by-digit stable sorting           |
| **8.4** | Bucket sort   | Expected linear time with uniform input |

---

## 8.1 Lower bounds for sorting

This short but very important section explains one of the most fundamental results in algorithm theory:

**Any comparison-based sorting algorithm must make at least Î©(n log n) comparisons in the worst case.**

This is why algorithms like merge sort, heapsort, and quicksort (average case) achieve Î˜(n log n) time â€” it's essentially the best possible using only comparisons.

### 1. The decision-tree model

Every comparison-based sorting algorithm can be modeled as a **binary decision tree**:

- **Each internal node** = one comparison (e.g., `A[i] â‰¤ A[j]?`)
- **Each branch** = yes/no answer
- **Each leaf** = one possible permutation of the input (the sorted order)

For **n distinct elements**, there are n! possible permutations â†’ the decision tree must have at least n! leaves.

### 2. Height of the decision tree = worst-case number of comparisons

A binary tree with at least L leaves must have height at least logâ‚‚ L.

Therefore, the height h (worst-case number of comparisons) satisfies:

```
h â‰¥ logâ‚‚ (number of leaves) â‰¥ logâ‚‚ (n!)
```

Using Stirling's approximation:

```
n! â‰ˆ âˆš(2Ï€n) (n/e)^n
logâ‚‚(n!) â‰ˆ n logâ‚‚ n âˆ’ n logâ‚‚ e + (1/2) logâ‚‚(2Ï€n)
```

- The **dominant term** is n logâ‚‚ n â†’

```
logâ‚‚(n!) = Î˜(n log n)
```

Thus:

**Any comparison-based sorting algorithm requires Î©(n log n) comparisons in the worst case.**

### 3. Important consequences

- Merge sort, heapsort â†’ **optimal up to constant factors (Î˜(n log n))**
- Quicksort average case â†’ **also optimal**
- Insertion sort, bubble sort, selection sort â†’ **not optimal (Î˜(nÂ²))**
- We **cannot do better than Î©(n log n)** using only pairwise comparisons

### 4. Linear-time sorting is possible â€” but not with comparisons

In later sections (8.2â€“8.4), we will see **counting sort, radix sort, and bucket sort**, which achieve **O(n)** or **O(n + k)** time.

- These algorithms do **not rely only on comparisons** â€” they use additional information about the input (e.g., integers in a limited range, floating-point numbers with known distribution).
- â†’ They **bypass the Î©(n log n) lower bound** because they are not comparison-based.

### Pseudocode â€“ Conceptual decision tree (not real code)

```text
// This is NOT executable code â€” just to show the idea

COMPARE-AND-BRANCH(A, i, j)
    if A[i] â‰¤ A[j]
        // left branch: continue with this assumption
        BRANCH-LEFT()
    else
        // right branch
        BRANCH-RIGHT()

// The full tree has n! leaves â€” each path from root to leaf is one possible sorting sequence
// Height â‰¥ logâ‚‚(n!) â‰ˆ n logâ‚‚ n
```

---

### TypeScript â€“ Approximate lower bound calculation

```ts
/**
 * Approximate the information-theoretic lower bound for comparison-based sorting
 * logâ‚‚(n!) â‰ˆ n logâ‚‚ n - n logâ‚‚ e + (1/2) logâ‚‚(2Ï€n)
 */
function sortingLowerBound(n: number): number {
  if (n <= 1) return 0;

  const log2 = Math.log2;

  // Stirling's approximation terms
  const term1 = n * log2(n);
  const term2 = -n * log2(Math.E);
  const term3 = 0.5 * log2(2 * Math.PI * n);

  return term1 + term2 + term3; // â‰ˆ logâ‚‚(n!)
}

// Examples
console.log("n = 10 â†’ minimum comparisons â‰ˆ", Math.ceil(sortingLowerBound(10))); // â‰ˆ 29
console.log(
  "n = 100 â†’ minimum comparisons â‰ˆ",
  Math.ceil(sortingLowerBound(100)),
); // â‰ˆ 525
console.log(
  "n = 1000 â†’ minimum comparisons â‰ˆ",
  Math.ceil(sortingLowerBound(1000)),
); // â‰ˆ 8523
```

---

### Summary Table â€“ Lower Bounds for Sorting

| Sorting type                                 | Time lower bound (worst case) | Reason / Technique used           |
| -------------------------------------------- | ----------------------------- | --------------------------------- |
| Any comparison-based sort                    | Î©(n log n)                    | Decision-tree model + logâ‚‚(n!)    |
| General comparison-based                     | Î©(n log n)                    | Same as above                     |
| Non-comparison-based (e.g., counting, radix) | O(n) or O(n + k)              | Uses extra information about keys |

---

### Key Takeaway

> The Î©(n log n) lower bound shows comparison-based sorting has a fundamental speed limit. Algorithms like merge sort and heapsort are **asymptotically optimal**.

---

## 8.2 Counting sort

Counting sort is a **non-comparison-based linear-time sorting algorithm**.
It works extremely well when the input consists of integers that fall within a **known small range** (say 0 to k).

---

### When to use Counting sort

- Input elements are integers (or can be mapped to small integers)
- Range of values k is not much larger than n (number of elements)
- We want **stable sorting** (equal elements keep their relative order)

---

### Core idea â€“ How it works

1. Count how many times each possible value appears in the array
2. Compute the **cumulative counts (prefix sums)** â†’ tells us the final position of each value
3. Build the sorted output by placing each element in its correct position (from right to left to maintain stability)

---

### Pseudocode (CLRS style â€“ 1-based indexing)

```text
COUNTING-SORT(A, B, n, k)               // A = input, B = output, k = max value
    let C[0..k] be a new array          // C[i] = count of i in A

    // Step 1: Count occurrences
    for j = 1 to n
        C[A[j]] â† C[A[j]] + 1

    // Step 2: Compute cumulative counts (positions)
    for i = 1 to k
        C[i] â† C[i] + C[i-1]

    // Step 3: Build sorted output (stable â€“ go backward)
    for j = n downto 1
        B[C[A[j]]] â† A[j]
        C[A[j]] â† C[A[j]] âˆ’ 1
```

---

### TypeScript code (0-based indexing â€“ practical version)

```ts
/**
 * Counting sort â€“ stable, O(n + k) time sorting for integers in range [0, k]
 * @param arr Input array of non-negative integers
 * @param maxValue The maximum possible value in the array (k)
 * @returns Sorted array (new array created)
 */
function countingSort(arr: number[], maxValue: number): number[] {
  const n = arr.length;
  const count = new Array(maxValue + 1).fill(0);
  const output = new Array(n);

  // Step 1: Count occurrences of each value
  for (const num of arr) {
    count[num]++;
  }

  // Step 2: Compute cumulative counts (prefix sums)
  for (let i = 1; i <= maxValue; i++) {
    count[i] += count[i - 1];
  }

  // Step 3: Build output array â€“ go backward for stability
  for (let j = n - 1; j >= 0; j--) {
    const value = arr[j];
    output[count[value] - 1] = value;
    count[value]--;
  }

  return output;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const numbers = [4, 2, 2, 8, 3, 3, 1];
const maxVal = Math.max(...numbers); // 8

console.log("Before:", numbers);
const sorted = countingSort(numbers, maxVal);
console.log("After: ", sorted);
// Output:
// Before: [4, 2, 2, 8, 3, 3, 1]
// After:  [1, 2, 2, 3, 3, 4, 8]
```

---

### Time and Space Complexity

| Aspect            | Complexity | Explanation                        |
| ----------------- | ---------- | ---------------------------------- |
| Time              | O(n + k)   | n = elements, k = range of values  |
| Space             | O(n + k)   | Output array + count array         |
| Comparison-based? | No         | Bypasses Î©(n log n) lower bound    |
| Stable?           | Yes        | Equal elements keep relative order |
| In-place?         | No         | Requires extra arrays              |

---

### When is Counting sort fast in practice?

- **k â‰ˆ n** or **k << n** â†’ very fast (linear time)
- Example: sorting **test scores (0â€“100)**, **pixel values (0â€“255)**, small integers, etc.

### Limitations

- Only works for integers (or values that can be mapped to small integers)
- If **k is very large** (e.g., k â‰ˆ 10â¹), it becomes impractical
- Not general-purpose like quicksort or merge sort

---

### Summary Table â€“ Counting sort at a glance

| Property                    | Value / Note                                             |
| --------------------------- | -------------------------------------------------------- |
| Best-case / Average / Worst | O(n + k) â€” always the same                               |
| Stable                      | Yes                                                      |
| In-place                    | No                                                       |
| Comparison-based?           | No                                                       |
| Best used when              | Small integer range (k â‰ˆ n or smaller)                   |
| Real-world examples         | Sorting grades, pixels, small keys, radix sort base case |

---

### Key Takeaway

> Counting sort **breaks the Î©(n log n) lower bound** by avoiding comparisons. It is **stable, linear-time, and simple** when the key range is reasonable.

---

## 8.3 Radix sort

Radix sort is a **non-comparison-based, stable, linear-time sorting algorithm** that extends the idea of counting sort to sort numbers (or strings) **digit by digit**, starting from the **least significant digit (LSD)** to the **most significant digit (MSD)**.

- **Time complexity:** O(d Â· (n + k))
  - n = number of elements
  - k = range of digit values (usually 10 for decimal, 256 for bytes, etc.)
  - d = number of digits in the largest number

When d is small (constant or logarithmic in n), this becomes O(n) â€” **beating the Î©(n log n) lower bound** for comparison-based sorting.

---

### Core idea â€“ How Radix Sort works (LSD version)

1. Treat each number as a sequence of digits (from right to left)
2. Use a **stable sorting subroutine** (usually counting sort) to sort the array by each digit position, one position at a time
3. Because the sort is stable, earlier sorts (lower digits) are preserved when sorting higher digits

---

### Pseudocode â€“ LSD Radix Sort

```text
RADIX-SORT(A, n, d)                     // A = array of n d-digit numbers
    for i = 1 to d                      // from least significant digit to most
        use a stable sort to sort A on digit i   // usually COUNTING-SORT
```

- COUNTING-SORT is used as the stable subroutine for each digit (modified to extract the i-th digit).

---

### TypeScript implementation (LSD Radix Sort â€“ decimal digits)

```ts
/**
 * Radix Sort (LSD - Least Significant Digit first)
 * Sorts non-negative integers in linear time O(d(n + k))
 * @param arr - array of non-negative integers to sort
 * @returns sorted array (new array)
 */
function radixSort(arr: number[]): number[] {
  if (arr.length <= 1) return [...arr];

  const max = Math.max(...arr);
  const maxDigits = max === 0 ? 1 : Math.floor(Math.log10(max)) + 1;

  let result = [...arr];

  for (let digit = 0; digit < maxDigits; digit++) {
    result = countingSortByDigit(result, digit);
  }

  return result;
}

/**
 * Stable counting sort by a specific digit position
 * @param arr input array
 * @param digit position (0 = least significant)
 */
function countingSortByDigit(arr: number[], digit: number): number[] {
  const n = arr.length;
  const output = new Array(n);
  const count = new Array(10).fill(0);

  for (const num of arr) {
    const currentDigit = Math.floor(num / Math.pow(10, digit)) % 10;
    count[currentDigit]++;
  }

  for (let i = 1; i < 10; i++) {
    count[i] += count[i - 1];
  }

  for (let j = n - 1; j >= 0; j--) {
    const num = arr[j];
    const currentDigit = Math.floor(num / Math.pow(10, digit)) % 10;
    output[count[currentDigit] - 1] = num;
    count[currentDigit]--;
  }

  return output;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const numbers = [329, 457, 657, 839, 436, 720, 355];
console.log("Before:", numbers);
const sorted = radixSort(numbers);
console.log("After: ", sorted);
// Output example:
// Before: [329, 457, 657, 839, 436, 720, 355]
// After:  [329, 355, 436, 457, 657, 720, 839]
```

---

### Time & Space Complexity

| Aspect            | Complexity   | Explanation                         |
| ----------------- | ------------ | ----------------------------------- |
| Time              | O(d (n + k)) | d passes Ã— counting sort (O(n + k)) |
| Linear when       | O(n)         | when d = O(1) or d = O(log n)       |
| Space             | O(n + k)     | Output + count array per pass       |
| Stable?           | Yes          | Uses stable counting sort           |
| In-place?         | No           | Requires extra space                |
| Comparison-based? | No           | Bypasses Î©(n log n) bound           |

---

### Practical notes

- Works best when numbers have **few digits (d small)**
- Common for **fixed-length integers** (32-bit, 64-bit), IP addresses, dates, etc.
- Often combined with **MSD radix sort** for strings or variable-length keys
- In practice, can be **faster than quicksort/merge sort** when d is small

---

### Summary Table â€“ Radix Sort at a glance

| Property            | Value / Note                                         |
| ------------------- | ---------------------------------------------------- |
| Time                | O(d (n + k)) â€” linear when d small                   |
| Stable              | Yes                                                  |
| In-place            | No                                                   |
| Best used when      | Fixed-length integers, small digit range, strings    |
| Real-world examples | Sorting 32-bit/64-bit integers, phone numbers, dates |

---

### Key Takeaway

> Radix sort is a **linear-time** algorithm that **breaks the comparison lower bound** by exploiting digit structure. It is **stable and fast** for suitable inputs.

---

## 8.4 Bucket sort

Bucket sort is another **non-comparison-based linear-time sorting algorithm**.
It works exceptionally well when the input is **uniformly distributed over a known range** (usually [0, 1)).

---

### Core Idea

1. Divide the range [0, 1) into n equal-sized buckets (or slightly more/less depending on implementation)
2. Distribute the n elements into these buckets according to their values
3. Sort each bucket individually (usually with **insertion sort** â€” because buckets are expected to be small)
4. Concatenate all buckets in order â†’ get the sorted array

### Why it works in linear time (expected)

- If the input numbers are uniformly and independently distributed in [0, 1),
  - each bucket is expected to contain O(1) elements on average.
  - Sorting each bucket with insertion sort takes O(1) expected time per bucket.

- â†’ Total expected time = O(n)

---

### Pseudocode (CLRS style â€“ assuming input in [0, 1))

```text
BUCKET-SORT(A, n)
    let B[0..n-1] be n empty lists (buckets)

    for i = 1 to n
        insert A[i] into list B[âŒŠn Â· A[i]âŒ‹]

    for i = 0 to n-1
        sort list B[i] using insertion sort

    concatenate lists B[0], B[1], ..., B[n-1] into A
```

---

### TypeScript implementation

```ts
/**
 * Bucket Sort â€“ expected O(n) time when input is uniformly distributed in [0, 1)
 * @param arr - array of numbers in range [0, 1)
 * @returns sorted array (new array created)
 */
function bucketSort(arr: number[]): number[] {
  const n = arr.length;
  if (n <= 1) return [...arr];

  const buckets: number[][] = Array.from({ length: n }, () => []);

  // Step 1: Distribute elements into buckets
  for (const num of arr) {
    const bucketIndex = Math.floor(n * num);
    buckets[bucketIndex].push(num);
  }

  // Step 2: Sort each bucket
  for (const bucket of buckets) {
    bucket.sort((a, b) => a - b);
  }

  // Step 3: Concatenate all buckets
  return buckets.flat();
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const input = [0.78, 0.17, 0.39, 0.26, 0.72, 0.94, 0.21, 0.12, 0.23, 0.68];
console.log("Before:", input);
const sorted = bucketSort(input);
console.log("After: ", sorted);
// Possible output:
// Before: [0.78, 0.17, 0.39, 0.26, 0.72, 0.94, 0.21, 0.12, 0.23, 0.68]
// After:  [0.12, 0.17, 0.21, 0.23, 0.26, 0.39, 0.68, 0.72, 0.78, 0.94]
```

---

### Time & Space Complexity

| Case                    | Time Complexity                | Explanation                                |
| ----------------------- | ------------------------------ | ------------------------------------------ |
| Average (uniform input) | Î˜(n)                           | Each bucket has O(1) elements â†’ O(n) total |
| Worst-case              | O(nÂ²)                          | All elements fall into one bucket          |
| Space                   | O(n)                           | Buckets + output                           |
| Stable?                 | Yes (if bucket sort is stable) | Depends on implementation                  |
| In-place?               | No                             | Requires extra space for buckets           |
| Comparison-based?       | No                             | Uses distribution information              |

---

### When Bucket Sort is very effective

- Input values are **uniformly distributed** in a known range
- Can afford O(n) extra space
- n is large, and we want **expected linear time**

### Practical notes

- Often used as a **subroutine** in other algorithms
- Works very well with **floating-point numbers normalized to [0,1)**
- Sometimes use more buckets (e.g., 1.5n or 2n) to reduce chance of large buckets
- If distribution is not uniform, **performance degrades**

---

### Summary Table â€“ Bucket sort at a glance

| Property                | Value / Note                                          |
| ----------------------- | ----------------------------------------------------- |
| Expected time (uniform) | Î˜(n)                                                  |
| Worst-case time         | O(nÂ²)                                                 |
| Stable                  | Yes (with stable bucket sort)                         |
| In-place                | No                                                    |
| Best used when          | Uniformly distributed numbers in [0,1)                |
| Real-world examples     | Sorting floating-point numbers, graphics, simulations |

---

### Key Takeaway

> Bucket sort is the **third major linear-time sorting algorithm** (after counting and radix sort). It relies on **uniform input distribution** and can be **extremely fast** when the assumption holds.
