# 33. Machine Learning Algorithms

## üìã Chapter Overview

This chapter covers three core ideas in modern machine learning algorithms:

- Clustering via the $k$-means algorithm
- Multiplicative-weights algorithms
- Gradient descent for optimization

---

## 33.1 Clustering (k-means)

Clustering is one of the most fundamental tasks in unsupervised learning. The goal is to group similar data points into clusters **without** labeled training data.

### Core Idea

Given a set of $n$ points in some space (usually $\mathbb{R}^d$), partition them into $k$ groups (clusters) such that:

- Points within the same cluster are similar to each other.
- Points in different clusters are dissimilar.

The standard $k$-means objective (distortion / inertia) is

$$
J = \sum_{i=1}^k \sum_{x \in C_i} \lVert x - \mu_i \rVert^2,
$$

where $C_i$ is the $i$-th cluster and $\mu_i$ is the mean (centroid) of cluster $C_i$.

This optimization problem is non-convex and hard to solve exactly, but the **$k$-means algorithm (Lloyd‚Äôs algorithm)** finds a good local minimum efficiently in practice.

### Lloyd‚Äôs $k$-means algorithm

1. **Initialization** ‚Äì choose $k$ initial centroids (randomly or with a better method like $k$-means++).
2. **Assignment step** ‚Äì assign each point to the nearest centroid (usually Euclidean distance).
3. **Update step** ‚Äì recompute each centroid as the mean of all points assigned to it.
4. Repeat steps 2‚Äì3 until convergence (centroids move very little or not at all).

Each iteration monotonically decreases (or leaves unchanged) the objective $J$, so the algorithm always converges.

### Properties

- **Time complexity**: roughly $O(n k d i)$, where
  - $n$ = number of points
  - $k$ = number of clusters
  - $d$ = dimension
  - $i$ = number of iterations (usually small)
- **Convergence**: guaranteed, but only to a **local** minimum.
- **Initialization-sensitive**: bad initial centroids can give poor clusters.
- **$k$-means++**: a smarter initialization that improves quality and speed.

### Pseudocode

```text
K-MEANS(X, k)
// X: set of n points in R^d, k: number of clusters

initialize k centroids Œº‚ÇÅ, Œº‚ÇÇ, ‚Ä¶, Œº‚Çñ   // random or k-means++

repeat until convergence
    // Assignment step
    for each point x ‚àà X
        assign x to cluster C‚±º where
            j = argmin_j ‚Äñx ‚àí Œº‚±º‚Äñ¬≤

    // Update step
    for each cluster j = 1 to k
        if C‚±º is not empty
            Œº‚±º ‚Üê (1 / |C‚±º|) ‚àë_{x ‚àà C‚±º} x

return clusters C‚ÇÅ, ‚Ä¶, C‚Çñ and centroids Œº‚ÇÅ, ‚Ä¶, Œº‚Çñ
```

### TypeScript ‚Äì simple 2D $k$-means

```ts
interface Point {
  x: number;
  y: number; // can be extended to more dimensions
}

/**
 * Simple k-means clustering (2D points for visualization)
 */
function kmeans(
  points: Point[],
  k: number,
  maxIterations: number = 100,
): { clusters: Point[][]; centroids: Point[] } {
  const n = points.length;
  if (n === 0 || k <= 0) {
    return { clusters: [], centroids: [] };
  }

  // Randomly initialize k centroids
  const centroids: Point[] = [];
  const usedIndices = new Set<number>();
  while (centroids.length < k) {
    const idx = Math.floor(Math.random() * n);
    if (!usedIndices.has(idx)) {
      usedIndices.add(idx);
      centroids.push({ ...points[idx] });
    }
  }

  let clusters: Point[][] = [];

  for (let iter = 0; iter < maxIterations; iter++) {
    // Assignment step: assign each point to nearest centroid
    clusters = Array.from({ length: k }, () => [] as Point[]);

    for (const p of points) {
      let bestCluster = 0;
      let minDist = Infinity;

      for (let j = 0; j < k; j++) {
        const dist = Math.hypot(p.x - centroids[j].x, p.y - centroids[j].y);
        if (dist < minDist) {
          minDist = dist;
          bestCluster = j;
        }
      }

      clusters[bestCluster].push(p);
    }

    // Update step: recompute centroids
    let changed = false;
    const newCentroids: Point[] = [];

    for (let j = 0; j < k; j++) {
      if (clusters[j].length === 0) {
        newCentroids.push(centroids[j]);
        continue;
      }

      let sumX = 0;
      let sumY = 0;
      for (const p of clusters[j]) {
        sumX += p.x;
        sumY += p.y;
      }

      const newX = sumX / clusters[j].length;
      const newY = sumY / clusters[j].length;

      if (
        Math.abs(newX - centroids[j].x) > 1e-6 ||
        Math.abs(newY - centroids[j].y) > 1e-6
      ) {
        changed = true;
      }

      newCentroids.push({ x: newX, y: newY });
    }

    for (let j = 0; j < k; j++) {
      centroids[j] = newCentroids[j];
    }

    if (!changed) {
      break; // converged
    }
  }

  return { clusters, centroids };
}

// Example usage
const points: Point[] = [
  { x: 1, y: 2 },
  { x: 1.5, y: 1.8 },
  { x: 1.2, y: 2.1 },
  { x: 5, y: 8 },
  { x: 5.5, y: 8.2 },
  { x: 4.8, y: 7.9 },
  { x: 9, y: 1 },
  { x: 8.8, y: 1.2 },
  { x: 9.2, y: 0.9 },
];

console.log("Running k-means with k=3");
const result = kmeans(points, 3);

console.log("\nFinal centroids:");
result.centroids.forEach((c, i) => {
  console.log(`Cluster ${i + 1}: (${c.x.toFixed(2)}, ${c.y.toFixed(2)})`);
});

console.log("\nCluster assignments:");
result.clusters.forEach((cluster, i) => {
  console.log(`Cluster ${i + 1} (${cluster.length} points):`);
  cluster.forEach((p) => console.log(`  (${p.x}, ${p.y})`));
});
```

### Important Notes

- Sensitive to initialization; $k$-means++ helps a lot in practice.
- Assumes Euclidean distance and roughly spherical, similarly-sized clusters.
- Struggles on elongated, non-convex, or very unbalanced clusters.
- Choosing $k$ is non-trivial: elbow method, silhouette score, gap statistic, etc.
- Very fast and scales to large datasets; has many variants (e.g., $k$-medoids, fuzzy $c$-means, Gaussian mixtures, spectral clustering).

### üìù Key Takeaway

$k$-means clusters data by alternately assigning points to the nearest centroid and recomputing centroids as means, minimizing within-cluster squared distances.

---

## 33.2 Multiplicative-Weights Algorithms

Multiplicative Weights (MW) is a simple and powerful **meta-algorithm** that appears in online learning, game theory, approximation algorithms, and more.

The idea:

- Maintain a weight distribution over a set of decisions (experts/options/strategies).
- After each round, increase weights of good decisions and decrease weights of bad ones **multiplicatively**.
- Use the current weighted combination to make the next decision.

### Core Setting ‚Äì Prediction with Expert Advice

We have:

- A set of $n$ experts.
- A sequence of $T$ rounds.
- In each round $t$:
  - Each expert $i$ outputs a prediction or decision.
  - Nature reveals losses $\ell_i^t \in [0,1]$ for each expert.
  - Our algorithm picks its own decision and suffers loss $\ell^t \in [0,1]$.

**Goal:** minimize regret versus the best single expert in hindsight.

Regret after $T$ rounds:

$$
	ext{Regret}_T = \Bigl(\text{our total loss}\Bigr)
                  - \min_i \Bigl(\text{loss of expert } i\Bigr).
$$

With a suitable learning rate $\eta$, MW achieves regret $O\bigl(\sqrt{T \log n}\bigr)$.

### Multiplicative-weights update rule

Maintain a weight $w_i^t$ for each expert $i$ at the beginning of round $t$.

- Initialize: $w_i^1 = 1$ for all $i$.
- At round $t$:
  1. Form distribution
     $$
     p_i^t = \frac{w_i^t}{W^t}, \quad W^t = \sum_i w_i^t.
     $$
  2. Predict using this distribution (e.g., randomized or weighted average).
  3. Observe losses $\ell_1^t, \dots, \ell_n^t \in [0,1]$.
  4. Update weights
     $$
     w_i^{t+1} = w_i^t (1 - \eta)^{\ell_i^t} = w_i^t \beta^{\ell_i^t},
     $$
     where $\beta = 1 - \eta$ and typically $\eta \approx \sqrt{\tfrac{\log n}{T}}$.

**Intuition**

- Good experts (low loss) get multiplied by a factor close to $1$ ‚Üí stay strong.
- Bad experts (high loss) get multiplied by a small factor ‚Üí their weight shrinks quickly.
- The algorithm tracks the best expert exponentially closely without committing too early.

### Pseudocode

```text
MULTIPLICATIVE-WEIGHTS-UPDATE(experts, T, Œ∑)

initialize w_i ‚Üê 1 for each expert i

for t ‚Üê 1 to T
    W ‚Üê ‚àë_i w_i

    // distribution over experts
    for each i
        p_i ‚Üê w_i / W

    Make prediction according to p (or pick argmax p_i)

    Observe losses ‚Ñì_i^t ‚àà [0,1] for each expert i

    // multiplicative update
    for each i
        w_i ‚Üê w_i √ó (1 ‚àí Œ∑)^{‚Ñì_i^t}
```

### TypeScript ‚Äì expert-advice MW

```ts
interface ExpertAdvice {
  predict: () => number; // expert predicts a value in [0, 1]
  name?: string;
}

/**
 * Multiplicative Weights algorithm for prediction with expert advice.
 */
function multiplicativeWeights(
  experts: ExpertAdvice[],
  T: number,
  eta: number,
  lossesPerRound: (t: number) => number[], // losses for all experts in round t
): number[] {
  const n = experts.length;
  const weights = new Array(n).fill(1);
  const algorithmLosses: number[] = [];

  for (let t = 1; t <= T; t++) {
    const totalWeight = weights.reduce((sum, w) => sum + w, 0);

    // Compute probability distribution
    const probs = weights.map((w) => w / totalWeight);

    // Algorithm makes weighted average prediction
    let algoPrediction = 0;
    for (let i = 0; i < n; i++) {
      algoPrediction += probs[i] * experts[i].predict();
    }

    // Get true losses from environment
    const losses = lossesPerRound(t);

    // Algorithm suffers (example) expected loss
    const expectedLoss = losses.reduce(
      (sum, loss, i) => sum + probs[i] * loss,
      0,
    );
    algorithmLosses.push(algoPrediction * expectedLoss);

    // Update weights multiplicatively
    for (let i = 0; i < n; i++) {
      weights[i] *= Math.pow(1 - eta, losses[i]);
    }
  }

  return algorithmLosses;
}

// Example: simple 3-expert setting
const experts: ExpertAdvice[] = [
  { predict: () => 0.2, name: "Expert A (pessimistic)" },
  { predict: () => 0.5, name: "Expert B (neutral)" },
  { predict: () => 0.8, name: "Expert C (optimistic)" },
];

const T = 20;
const eta = 0.3;

// Simulated environment: true probability drifts from 0.3 to 0.7
const lossesPerRound = (t: number) => {
  const trueProb = 0.3 + 0.4 * (t / T);
  return experts.map((e) => Math.abs(e.predict() - trueProb));
};

console.log("Running Multiplicative Weights for", T, "rounds");
const algoLosses = multiplicativeWeights(experts, T, eta, lossesPerRound);

console.log("\nAlgorithm losses per round:");
console.log(
  algoLosses.map((l, i) => `Round ${i + 1}: ${l.toFixed(4)}`).join("\n"),
);

const totalAlgoLoss = algoLosses.reduce((sum, l) => sum + l, 0);
console.log("\nTotal algorithm loss:", totalAlgoLoss.toFixed(4));
```

### Important Notes

- Regret bound $O\bigl(\sqrt{T \log n}\bigr)$ is (essentially) optimal in many settings.
- Learning rate $\eta \approx \sqrt{\tfrac{\log n}{T}}$ achieves this bound.
- Works for losses in $[0,1]$; extends to more general bounded losses.
- Appears under many names: weighted majority, Hedge, AdaBoost, etc.
- Extremely simple to implement yet very powerful and general.

### üìù Key Takeaway

Maintain weights over experts, predict with the weighted distribution, and update weights multiplicatively according to losses to obtain sublinear regret.

---

## 33.3 Gradient Descent

Gradient descent is one of the most important and widely used optimization algorithms in machine learning and numerical computing. It is the backbone of training most neural networks and many other models.

### Core Idea

We want to minimize a differentiable function $f : \mathbb{R}^n \to \mathbb{R}$, often a loss or cost function.

Starting from an initial point $x_0$, repeat:

$$
x_{t+1} \leftarrow x_t - \eta \, \nabla f(x_t),
$$

where $\eta > 0$ is the learning rate.

Stop when $\lVert \nabla f(x_t) \rVert$ is small or when the change in $x_t$ becomes tiny.

### Variants

- **Batch gradient descent** ‚Äì uses the exact gradient over all data.
- **Stochastic gradient descent (SGD)** ‚Äì uses one random example per step.
- **Mini-batch gradient descent** ‚Äì uses a small batch (e.g., 32, 64, 128 samples).

Batch is accurate but slow on large datasets; SGD/mini-batch are faster and often converge faster in wall-clock time, though with a noisier path.

### Convergence (Basic Theory)

Assume $f$ is convex and $L$-smooth (gradient is Lipschitz), with $\eta \le 1/L$:

- Convex: converges to a global minimum.
- Strongly convex: converges linearly.
- Non-convex (typical in deep learning): converges to a stationary point $\nabla f \approx 0$ (often a good local minimum in practice).

### Pseudocode

```text
GRADIENT-DESCENT(f, ‚àáf, x‚ÇÄ, Œ∑, maxIter, tol)

x ‚Üê x‚ÇÄ

for t ‚Üê 1 to maxIter
    g ‚Üê ‚àáf(x)                 // compute gradient

    if ‚Äñg‚Äñ‚ÇÇ < tol
        break                 // converged

    x ‚Üê x ‚àí Œ∑ ¬∑ g             // update

return x
```

Mini-batch / SGD version:

```text
x ‚Üê x‚ÇÄ

for each epoch
    shuffle training data

    for each mini-batch B
        g ‚Üê (1 / |B|) ‚àë_{i ‚àà B} ‚àáf_i(x)   // average gradient
        x ‚Üê x ‚àí Œ∑ ¬∑ g
```

### TypeScript ‚Äì gradient descent on a quadratic

We minimize

$$
f(x) = \tfrac{1}{2} x^\top Q x - b^\top x,
$$

where the minimum is at $x^* = Q^{-1} b$ when $Q$ is positive definite.

```ts
/**
 * Gradient descent to minimize f(x) = 1/2 x^T Q x - b^T x
 * for a positive definite Q.
 */
function gradientDescent(
  Q: number[][], // positive definite matrix (n√ón)
  b: number[], // linear term
  x0: number[], // starting point
  learningRate = 0.01,
  maxIter = 1000,
  tolerance = 1e-6,
): { solution: number[]; iterations: number } {
  const n = x0.length;
  const x = [...x0];
  let iter = 0;

  while (iter < maxIter) {
    // Compute gradient: ‚àáf(x) = Qx - b
    const grad = new Array<number>(n).fill(0);

    for (let i = 0; i < n; i++) {
      for (let j = 0; j < n; j++) {
        grad[i] += Q[i][j] * x[j];
      }
      grad[i] -= b[i];
    }

    // Check norm of gradient
    const gradNorm = Math.sqrt(grad.reduce((sum, v) => sum + v * v, 0));
    if (gradNorm < tolerance) {
      break;
    }

    // Update: x ‚Üê x - Œ∑ ‚àáf(x)
    for (let i = 0; i < n; i++) {
      x[i] -= learningRate * grad[i];
    }

    iter++;
  }

  return { solution: x, iterations: iter };
}

// Example: minimize f(x, y) = 2x¬≤ + 2xy + 2y¬≤ ‚àí 6x ‚àí 8y
// Q = [[4, 2], [2, 4]], b = [6, 8]; minimum at (1, 1)

const Q = [
  [4, 2],
  [2, 4],
];

const b = [6, 8];
const x0 = [0, 0];

console.log("Running gradient descent...");

const result = gradientDescent(Q, b, x0, 0.05, 500, 1e-5);

console.log(
  "Solution:",
  result.solution.map((v) => v.toFixed(6)),
);
console.log("Iterations:", result.iterations);
console.log("Final point should be close to (1, 1)");
```

### Important Notes

- Choosing the learning rate $\eta$ is critical:
  - Too large ‚Üí divergence or oscillation.
  - Too small ‚Üí very slow convergence.
- Modern optimizers (momentum, RMSprop, Adam, etc.) adaptively adjust steps and are much more robust.
- SGD / mini-batch methods are essential for large-scale datasets.
- In non-convex problems, we typically reach a good local minimum, not necessarily global.
- Requires a differentiable objective (or subgradients in the non-smooth case).

### üìù Key Takeaway

Gradient descent repeatedly moves opposite the gradient with a suitable step size. It is the basic building block behind almost all modern learning algorithms.
