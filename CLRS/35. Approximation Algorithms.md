# 35. Approximation Algorithms

## üìã Chapter Overview

Summaries and code sketches for classic approximation algorithms from CLRS, with emphasis on structure, intuition, and TypeScript implementations.

- 35.1 Vertex cover: simple 2-approximation and its tight analysis
- Additional classic approximation patterns in later sections (e.g., set cover, TSP variants)

---

## 35.1 Vertex-Cover Problem

### Problem Definition

- **Input (decision version):**
  - Undirected graph $G = (V, E)$
  - Integer $k$
- **Question:** Does there exist a vertex cover $C \subseteq V$ with $|C| \le k$?
- **Vertex cover:** A set $C \subseteq V$ such that every edge $e = (u, v) \in E$ has at least one endpoint in $C$.

**Optimization version (typically approximated):**

- Find a vertex cover $C$ of **minimum possible size**.
- The problem is **NP-complete** (via reduction from 3-SAT, Clique, etc.).

### 2-Approximation Algorithm

High-level idea: repeatedly pick an uncovered edge and add **both** its endpoints to the cover.

#### Pseudocode

```text
APPROX-VERTEX-COVER(G = (V, E))
    C  ‚Üê ‚àÖ                 // the cover we are building
    E' ‚Üê copy of E         // working set of edges

    while E' is not empty
        pick any edge (u, v) from E'
        C ‚Üê C ‚à™ {u, v}
        remove from E' every edge incident on u or v

    return C
```

### Why It Is a 2-Approximation

Let **OPT** be the size of a minimum vertex cover.
Let **C** be the cover produced by the algorithm.

1. **C is a valid vertex cover**
   - Whenever we pick an edge $(u, v)$, we add both $u$ and $v$ to $C$.
   - Then we remove every edge incident on $u$ or $v$; all those edges are now covered.
   - Every original edge is eventually removed this way, so every edge is incident on some vertex in $C$.

2. **Approximation bound $|C| \le 2 \cdot \text{OPT}$**
   - Each iteration chooses some edge $(u, v)$ from the **current** set $E'$ and then deletes **all** edges incident to $u$ or $v$.
   - Therefore, no edge chosen in one iteration shares an endpoint with an edge chosen in any other iteration.
   - The set of picked edges $M$ is therefore a **matching** (edges are pairwise disjoint).
   - In each iteration we add both endpoints of one matching edge to $C$, so $|C| = 2|M|$.
   - Any vertex cover must include at least **one endpoint of every edge in $M$**, hence any vertex cover has size at least $|M|$.
     $$ \text{OPT} \ge |M| = \frac{|C|}{2} $$
   - Rearranging: $|C| \le 2 \cdot \text{OPT}$.

So this algorithm is a **2-approximation**: its solution is at most twice the optimum size.

### Tightness of the Bound

- The factor **2 is tight** for this algorithm.
- There are graphs (e.g., complete bipartite graphs $K_{n,n}$ with a suitable edge-selection order) where the algorithm returns a cover almost exactly twice as large as the optimal one.

### TypeScript: 2-Approximation Vertex Cover

```ts
interface Graph {
  vertices: number;
  edges: [number, number][];
}

/**
 * 2-Approximation algorithm for Vertex Cover
 * Returns a vertex cover C with size ‚â§ 2 √ó OPT (theoretically).
 */
function approxVertexCover(graph: Graph): number[] {
  const { edges } = graph;
  const cover = new Set<number>();

  // Working copy of edges, stored canonically as "min,max"
  const remainingEdges = new Set<string>(
    edges.map(([u, v]) => `${Math.min(u, v)},${Math.max(u, v)}`),
  );

  while (remainingEdges.size > 0) {
    // Pick any remaining edge
    const edgeStr = remainingEdges.values().next().value as string;
    const [u, v] = edgeStr.split(",").map(Number);

    // Add both endpoints to the cover
    cover.add(u);
    cover.add(v);

    // Remove all edges incident to u or v
    const toRemove: string[] = [];

    for (const e of remainingEdges) {
      const [a, b] = e.split(",").map(Number);
      if (a === u || a === v || b === u || b === v) {
        toRemove.push(e);
      }
    }

    for (const e of toRemove) {
      remainingEdges.delete(e);
    }
  }

  return Array.from(cover);
}

// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Example usage
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

const graph: Graph = {
  vertices: 7,
  edges: [
    [0, 1],
    [0, 2],
    [1, 2], // triangle
    [1, 3],
    [2, 4],
    [3, 5],
    [4, 5],
    [5, 6],
  ],
};

console.log("Graph edges:", graph.edges);

const cover = approxVertexCover(graph);
console.log("Approximate vertex cover:", cover);
console.log("Size of cover:", cover.length);

// In this graph, optimal vertex cover size = 3.
// The algorithm typically returns size 4 or 5 (‚â§ 2 √ó OPT).
```

### üìù Key Takeaway

- Vertex cover is NP-complete, but admits a **very simple 2-approximation**.
- The proof uses the fact that the edges chosen by the algorithm form a **matching**.
- The factor 2 is **tight** for this greedy strategy.

---

## 35.2 Traveling-Salesperson Problem (TSP)

### Problem Definition

- **Input:** Complete graph $G = (V, E)$ with nonnegative edge weights $c(u, v)$ (distances between cities).
- **Goal:** Find a tour that
  - visits every vertex exactly once, and
  - returns to the starting vertex,
    with **minimum total weight**.

Decision version (‚ÄúIs there a tour of length $\le B$?‚Äù) is **NP-complete**; the optimization version is **NP-hard**.

### Two Main Variants

1. **General TSP**
   - Edge weights are arbitrary (even negative in some formulations).
   - **No constant-factor approximation** exists unless $\text{P} = \text{NP}$.

2. **Metric TSP**
   - Edge weights satisfy the **triangle inequality**:
     $$ c(u, v) \le c(u, w) + c(w, v) \quad \forall u, v, w. $$
   - Models most realistic cases (Euclidean distances, road networks, etc.).
   - For metric TSP, good approximation algorithms exist.

### 2-Approximation via MST + Tree Walk

For **metric TSP**, CLRS presents a simple **2-approximation**:

```text
APPROX-TSP-TOUR(G, c)
    1. Compute a minimum spanning tree (MST) T of G
    2. Let L be the list of vertices visited by a preorder tree walk of T
       (each MST edge is traversed exactly twice)
    3. Shortcut repeated vertices in L (remove duplicates, preserving order)
       to obtain a Hamiltonian cycle H
    4. Return H
```

#### Why It Is a 2-Approximation

Let **OPT** be the cost of an optimal TSP tour.

1. If we remove any one edge from an optimal TSP tour, we get a **spanning tree** of $G$.
   - So $\text{cost(MST)} \le \text{OPT}$.
2. In the preorder tree walk, each MST edge is traversed **twice**.
   - So $\text{cost}(L) \le 2 \cdot \text{cost(MST)} \le 2 \cdot \text{OPT}$.
3. When we **shortcut** repeated vertices using triangle inequality, we never increase the length.
   - So $\text{cost}(H) \le \text{cost}(L) \le 2 \cdot \text{OPT}$.

Thus the tour $H$ has length at most twice optimal.

### Christofides‚Äô Algorithm (1.5-Approximation)

Outline (more complex, but better ratio):

1. Compute an MST $T$.
2. Find a **minimum-weight perfect matching** $M$ on the odd-degree vertices of $T$.
3. Combine $T \cup M$ to obtain an **Eulerian multigraph**.
4. Find an Eulerian tour and shortcut it (using triangle inequality) to get a Hamiltonian cycle.

This gives a **1.5-approximation** for metric TSP ‚Äî the best known polynomial-time guarantee.

### TypeScript: 2-Approximation for Euclidean TSP

```ts
// Simplified 2-approximation for metric TSP (Euclidean points).

interface Point {
  x: number;
  y: number;
}

/**
 * Very simple 2-approximation for Euclidean TSP
 * using MST + preorder tree walk + shortcutting.
 */
function approxTSP(points: Point[]): number[] {
  const n = points.length;
  if (n <= 1) return [];

  // Step 1: compute distance matrix
  const dist = Array.from({ length: n }, () => Array(n).fill(0));
  for (let i = 0; i < n; i++) {
    for (let j = i + 1; j < n; j++) {
      const d = Math.hypot(
        points[i].x - points[j].x,
        points[i].y - points[j].y,
      );
      dist[i][j] = dist[j][i] = d;
    }
  }

  // Step 2: build MST via Prim's algorithm (simple O(n^2) version)
  const parent = new Array<number>(n).fill(-1);
  const key = new Array<number>(n).fill(Infinity);
  const inMST = new Array<boolean>(n).fill(false);

  key[0] = 0;

  for (let count = 0; count < n; count++) {
    // Pick vertex u with minimal key not yet in MST
    let u = -1;
    let min = Infinity;
    for (let v = 0; v < n; v++) {
      if (!inMST[v] && key[v] < min) {
        min = key[v];
        u = v;
      }
    }

    if (u === -1) break;
    inMST[u] = true;

    for (let v = 0; v < n; v++) {
      if (!inMST[v] && dist[u][v] < key[v]) {
        key[v] = dist[u][v];
        parent[v] = u;
      }
    }
  }

  // Step 3: build adjacency list of MST
  const adj: number[][] = Array.from({ length: n }, () => []);
  for (let i = 1; i < n; i++) {
    if (parent[i] !== -1) {
      adj[parent[i]].push(i);
      adj[i].push(parent[i]);
    }
  }

  // Step 4: preorder DFS tree walk to get tour
  const visited = new Array<boolean>(n).fill(false);
  const tour: number[] = [];

  function dfs(u: number) {
    visited[u] = true;
    tour.push(u);
    for (const v of adj[u]) {
      if (!visited[v]) dfs(v);
    }
  }

  dfs(0);

  // Step 5: shortcut duplicates and close the tour
  const uniqueTour: number[] = [];
  const seen = new Set<number>();

  for (const v of tour) {
    if (!seen.has(v)) {
      seen.add(v);
      uniqueTour.push(v);
    }
  }

  // Return to the start
  uniqueTour.push(uniqueTour[0]);
  return uniqueTour;
}

// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Example usage
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

const cities: Point[] = [
  { x: 0, y: 0 },
  { x: 2, y: 3 },
  { x: 5, y: 1 },
  { x: 6, y: 4 },
  { x: 1, y: 5 },
];

console.log(
  "Cities:",
  cities.map((p, i) => `${i}: (${p.x}, ${p.y})`),
);

const tour = approxTSP(cities);
console.log("\nApproximate TSP tour (indices):", tour);
console.log(
  "Tour path:",
  tour.map((i) => `(${cities[i].x}, ${cities[i].y})`),
);
```

### üìù Key Takeaway

- Metric TSP admits a simple **2-approximation** via MST + preorder tree walk.
- Triangle inequality is crucial to argue that **shortcutting** does not increase tour length.
- Christofides‚Äô algorithm improves the factor to **1.5**, but is more complex.

---

## 35.3 Set-Covering Problem

### Problem Definition

- **Universe:** $U = \{1, 2, \dots, n\}$
- **Subsets:** $S_1, S_2, \dots, S_m \subseteq U$

**Goal (optimization version):**

- Choose the smallest number of these subsets whose union equals $U$.

**Decision version (NP-complete):**

- Given integer $k$, is there a subcollection of at most $k$ sets that covers $U$?

### Greedy Approximation Algorithm

Idea: repeatedly pick the set that covers the largest number of **currently uncovered** elements.

```text
GREEDY-SET-COVER(U, S = {S‚ÇÅ, ‚Ä¶, S‚Çò})
    C       ‚Üê ‚àÖ        // selected sets
    covered ‚Üê ‚àÖ        // covered elements so far

    while covered ‚â† U
        bestSet   ‚Üê null
        bestCount ‚Üê 0

        for each S‚±º in S that has not yet been picked
            newCovered ‚Üê |S‚±º \ covered|
            if newCovered > bestCount
                bestCount ‚Üê newCovered
                bestSet   ‚Üê S‚±º

        if bestSet = null
            break      // cannot cover more elements

        C       ‚Üê C ‚à™ {bestSet}
        covered ‚Üê covered ‚à™ bestSet

    return C
```

### Approximation Guarantee

- Let **OPT** be the size of a minimum set cover.
- The greedy algorithm returns a cover **C** satisfying
  $$ |C| \le (\ln n + 1) \cdot \text{OPT}. $$
- This is a **(ln n + 1)-approximation**.

**Intuition of the proof (charging argument):**

- Each time we pick a set, we "charge" cost 1 to the newly covered elements.
- Each newly covered element is charged proportionally to how many elements remain uncovered.
- For any element, the total charge it could accumulate over the process is at most the harmonic number
  $$ H_n = 1 + \frac{1}{2} + \cdots + \frac{1}{n} \approx \ln n + 1. $$
- Summing over all elements and comparing to OPT yields the bound.

### TypeScript: Greedy Set Cover

```ts
/**
 * Greedy approximation for set cover.
 * @param universe - array of all elements (1..n or any identifiers)
 * @param sets - array of subsets (each subset is an array of elements)
 * @returns array of selected set indices (0-based) that approximately cover the universe
 */
function greedySetCover<T>(universe: T[], sets: T[][]): number[] {
  const uncovered = new Set(universe);
  const selected: number[] = [];

  while (uncovered.size > 0) {
    let bestSetIndex = -1;
    let bestNewCount = 0;

    // Find set that covers the most uncovered elements
    for (let i = 0; i < sets.length; i++) {
      if (selected.includes(i)) continue; // skip already chosen sets

      let newCount = 0;
      for (const elem of sets[i]) {
        if (uncovered.has(elem)) newCount++;
      }

      if (newCount > bestNewCount) {
        bestNewCount = newCount;
        bestSetIndex = i;
      }
    }

    // No more elements can be covered
    if (bestSetIndex === -1 || bestNewCount === 0) break;

    selected.push(bestSetIndex);

    // Remove covered elements
    for (const elem of sets[bestSetIndex]) {
      uncovered.delete(elem);
    }
  }

  return selected;
}

// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Example usage
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

const universe = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

const sets = [
  [1, 2, 3, 4], // S0
  [3, 4, 5, 6], // S1
  [5, 6, 7, 8], // S2
  [7, 8, 9, 10], // S3
  [1, 5, 9], // S4
  [2, 6, 10], // S5
];

console.log("Universe:", universe);
console.log("Sets:");
sets.forEach((s, i) => console.log(`S${i}:`, s));

const coverIndices = greedySetCover(universe, sets);
console.log("\nGreedy selected set indices:", coverIndices);

const coveredElements = new Set<number>();
coverIndices.forEach((i) => {
  sets[i].forEach((elem) => coveredElements.add(elem));
});

console.log("Covered elements:", Array.from(coveredElements));
console.log("Cover size:", coverIndices.length);
// Typical output: selects around 3‚Äì4 sets (OPT = 3 in this example).
```

### üìù Key Takeaway

- Greedy set cover is a **(ln n + 1)-approximation**, and this factor is **asymptotically tight**.
- Despite the worst-case bound, the greedy heuristic often performs much better in practice.
- Many real-world tasks (database query optimization, facility location, sensor placement, etc.) reduce to set cover.

---

## 35.4 Randomization and Linear Programming (Max-Cut)

### Core Problem: Max-Cut

- **Input:** Undirected graph $G = (V, E)$ with nonnegative edge weights $w(e)$.
- **Goal:** Find a cut $(S, V \setminus S)$ maximizing the total weight of edges crossing the cut.
- Max-Cut is **NP-hard** (even for unweighted graphs).

### LP Relaxation and Randomized Rounding (Conceptual)

We relax Max-Cut to a linear (or convex) program, solve it, then **round** the fractional solution randomly.

One LP-style relaxation (schematic):

- Assign a variable $x_i \in [0, 1]$ to each vertex $v_i$ indicating its "side" of the cut (fractionally).
- Maximize an objective that approximates the cut weight, e.g.
  $$ \sum*{(i,j) \in E} w*{ij} \bigl(x_i (1 - x_j) + x_j (1 - x_i)\bigr). $$

After solving the relaxation, we obtain an optimal fractional solution $x^*$.

**Randomized rounding:**

- For each vertex $i$ independently:
  - Put $v_i$ in $S$ with probability $x_i^*$.
  - Put $v_i$ in $V \setminus S$ with probability $1 - x_i^*$.
- Output the cut $(S, V \setminus S)$.

### Approximation Ratio (High Level)

- For each edge $(i, j)$ with weight $w_{ij}$, the probability that it is cut is
  $$ \Pr[\text{edge } (i, j) \text{ is cut}] = x*i^* (1 - x*j^*) + x*j^* (1 - x*i^*). $$
- The **expected** contribution of this edge to the cut is
  $$ w*{ij} \cdot \Pr[\text{edge is cut}] = w*{ij} (x*i^* + x*j^* - 2 x*i^* x*j^*). $$
- By comparing this expectation with the value of the relaxation (and using stronger relaxations such as semidefinite programming), one can obtain a constant-factor approximation.

The famous **Goemans‚ÄìWilliamson algorithm** (using semidefinite programming and a geometric rounding scheme) achieves an approximation factor of

$$\alpha \approx 0.87856,$$

which is still the best known polynomial-time guarantee for Max-Cut.

### Pseudocode (Randomized Rounding Skeleton)

```text
RANDOMIZED-MAX-CUT-LP(G = (V, E), w)
    1. Formulate and solve an LP (or SDP) relaxation of Max-Cut
    2. Let x* be the optimal fractional solution
    3. Initialize S ‚Üê ‚àÖ and T ‚Üê ‚àÖ  (T will represent V \ S)
    4. For each vertex i ‚àà V independently:
           with probability x*_i put v_i in S
           otherwise put v_i in T
    5. Return cut (S, T)
```

### TypeScript: Rounding Step (Conceptual Only)

```ts
interface MaxCutGraph {
  vertices: number;
  edges: { u: number; v: number; weight: number }[];
}

/**
 * Randomized rounding for a Max-Cut relaxation.
 * Assumes we already solved the relaxation and have a fractional assignment x*.
 */
function randomizedMaxCutRounding(
  graph: MaxCutGraph,
  fractionalX: number[], // x*[i] ‚àà [0,1] for vertex i
): { cut: [number[], number[]]; cutValue: number } {
  const S: number[] = [];
  const VminusS: number[] = [];

  // Randomized rounding: put vertex i in S with probability x*[i]
  for (let i = 0; i < graph.vertices; i++) {
    if (Math.random() < fractionalX[i]) {
      S.push(i);
    } else {
      VminusS.push(i);
    }
  }

  // Compute cut value
  let cutValue = 0;
  const inS = new Set(S);

  for (const edge of graph.edges) {
    const uInS = inS.has(edge.u);
    const vInS = inS.has(edge.v);
    if (uInS !== vInS) {
      cutValue += edge.weight;
    }
  }

  return { cut: [S, VminusS], cutValue };
}

// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Example usage (fractional solution assumed from solver)
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

const graph: MaxCutGraph = {
  vertices: 5,
  edges: [
    { u: 0, v: 1, weight: 1 },
    { u: 0, v: 2, weight: 2 },
    { u: 1, v: 3, weight: 3 },
    { u: 2, v: 4, weight: 4 },
    { u: 3, v: 4, weight: 1 },
  ],
};

// Hypothetical fractional LP/SDP solution
const fractionalX = [0.1, 0.9, 0.3, 0.7, 0.2];

console.log("Running randomized rounding for Max-Cut");
const result = randomizedMaxCutRounding(graph, fractionalX);
console.log("Cut sets:", result.cut);
console.log("Cut value:", result.cutValue);
```

### üìù Key Takeaway

- Max-Cut is NP-hard but admits **good approximation algorithms** using relaxations + randomized rounding.
- The Goemans‚ÄìWilliamson SDP-based algorithm achieves an approximation ratio of about **0.87856**.
- Randomized rounding is a powerful general technique: solve a relaxed problem, then round the fractional solution probabilistically while preserving a good expected objective value.
