# 14. Dynamic Programming

## üìã Chapter Overview

| Section  | Topic                       | Key Idea                                       |
| -------- | --------------------------- | ---------------------------------------------- |
| **14.1** | Rod cutting                 | Optimal substructure + overlapping subproblems |
| **14.2** | Matrix-chain multiplication | Optimal parenthesization                       |
| **14.3** | Elements of DP              | When DP applies + top-down/bottom-up           |
| **14.4** | Longest common subsequence  | 2D DP table for sequence alignment             |
| **14.5** | Optimal BSTs                | Minimize expected search cost                  |

---

## 14.1 Rod Cutting

The rod-cutting problem is the classic first example of dynamic programming.

### Problem Statement

Given a rod of length `n` and a table of prices `p[i]` where:

- `p[i]` = price we get if we sell a piece of length `i`
- We can make zero or more cuts ‚Üí decide where to cut (or not cut at all)

**Goal:** Maximize total revenue we can get by cutting and selling the pieces.

**Example Price Table (CLRS classic)**
| Length i | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |
|------------|---|---|---|---|---|---|---|---|---|----|
| Price p[i] | 1 | 5 | 8 | 9 | 10 | 17 | 17 | 20 | 24 | 30 |

### Two Main Approaches

- Top-down with memoization (recursive + caching)
- Bottom-up (iterative dynamic programming table)

Both give the same correct answer ‚Äî only the computation order differs.

---

### 1. Recursive Idea (Naive)

**Recursive Relation:**

```

r[n] = max {
p[n],                // no cut at all
p[1] + r[n-1],
p[2] + r[n-2],
...
p[k] + r[n-k]  for k = 1 to n
}

```

**Base Case:** `r[0] = 0` (zero length rod gives zero revenue)

**Naive Recursive Pseudocode (Exponential Time)**

```

CUT-ROD(p, n)
if n == 0
return 0
q ‚Üê -‚àû
for i ‚Üê 1 to n
q ‚Üê max(q, p[i] + CUT-ROD(p, n-i))
return q

```

---

### 2. Top-Down with Memoization

Cache results so each subproblem is solved only once.

**Pseudocode (Top-Down Memoized)**

```

MEMOIZED-CUT-ROD(p, n)
let r[0..n] be a new array
for i ‚Üê 0 to n
r[i] ‚Üê -‚àû
return MEMOIZED-CUT-ROD-AUX(p, n, r)

MEMOIZED-CUT-ROD-AUX(p, n, r)
if r[n] ‚â• 0
return r[n]
if n == 0
q ‚Üê 0
else
q ‚Üê -‚àû
for i ‚Üê 1 to n
q ‚Üê max(q, p[i] + MEMOIZED-CUT-ROD-AUX(p, n-i, r))
r[n] ‚Üê q
return q

```

---

### 3. Bottom-Up Dynamic Programming (Recommended)

Fill a table from smallest length to largest.

**Pseudocode (Bottom-Up)**

```

BOTTOM-UP-CUT-ROD(p, n)
let r[0..n] be a new array
r[0] ‚Üê 0
for j ‚Üê 1 to n
q ‚Üê -‚àû
for i ‚Üê 1 to j
q ‚Üê max(q, p[i] + r[j-i])
r[j] ‚Üê q
return r[n]

```

**TypeScript Implementation**

```ts
/**
 * Bottom-up rod cutting ‚Äì O(n¬≤) time, O(n) space
 * Returns only the maximum revenue
 */
function bottomUpCutRod(p: number[], n: number): number {
  const r: number[] = new Array(n + 1);
  r[0] = 0;

  for (let j = 1; j <= n; j++) {
    let q = -Infinity;
    for (let i = 1; i <= j; i++) {
      q = Math.max(q, p[i] + r[j - i]);
    }
    r[j] = q;
  }

  return r[n];
}

// Extended version to get optimal cuts
function extendedBottomUpCutRod(
  p: number[],
  n: number,
): { revenue: number; cuts: number[] } {
  const r: number[] = new Array(n + 1);
  const s: number[] = new Array(n + 1); // s[j] = optimal first cut size for length j
  r[0] = 0;

  for (let j = 1; j <= n; j++) {
    let q = -Infinity;
    for (let i = 1; i <= j; i++) {
      if (q < p[i] + r[j - i]) {
        q = p[i] + r[j - i];
        s[j] = i;
      }
    }
    r[j] = q;
  }

  // Reconstruct the cuts
  const cuts: number[] = [];
  let remaining = n;
  while (remaining > 0) {
    cuts.push(s[remaining]);
    remaining -= s[remaining];
  }

  return { revenue: r[n], cuts };
}

// Example (CLRS table)
const prices = [0, 1, 5, 8, 9, 10, 17, 17, 20, 24, 30];

console.log("Max revenue for length 4:", bottomUpCutRod(prices, 4)); // 10
console.log("Max revenue for length 10:", bottomUpCutRod(prices, 10)); // 30

const result = extendedBottomUpCutRod(prices, 10);
console.log("Revenue:", result.revenue); // 30
console.log("Possible cuts:", result.cuts); // e.g. [2,2,6] or [3,3,4]
```

---

### Important Notes

- **Time complexity:** O(n¬≤) (for loop 1 to n √ó inner loop 1 to j)
- **Space:** O(n) (can be optimized to O(1) if only value is needed)
- **Optimal cuts:** Use extra array `s[]` to reconstruct actual cuts

### Key Takeaway

> Rod cutting demonstrates **optimal substructure** and **overlapping subproblems**. Both **top-down** memoization and **bottom-up** DP yield the same optimal revenue, with bottom-up typically cleaner in practice.

---

## 14.2 Matrix-Chain Multiplication

This is the classic second example of dynamic programming ‚Äî right after rod cutting.

### Problem Statement

We are given a sequence of matrices to multiply:

```

A‚ÇÅ √ó A‚ÇÇ √ó ‚Ä¶ √ó A‚Çô

```

- Each matrix `A·µ¢` has dimensions `p_{i-1} √ó p·µ¢`
- Goal: Find the parenthesization (order of multiplications) that minimizes the total number of scalar multiplications.

**Key Points:**

- Matrix multiplication is **associative** ‚Äî but **not commutative**.
- The cost depends heavily on the order of multiplication.

### Motivating Example

Matrices: `A (10√ó100) √ó B (100√ó5) √ó C (5√ó50)`

- `(A √ó B) √ó C` ‚Üí Cost = 10¬∑100¬∑5 + 10¬∑5¬∑50 = 5000 + 2500 = 7500
- `A √ó (B √ó C)` ‚Üí Cost = 100¬∑5¬∑50 + 10¬∑100¬∑50 = 25000 + 50000 = 75000

> Same result, 10√ó difference in cost ‚Äî order matters a lot!

### Recursive Structure (Optimal Substructure)

To compute the minimum cost to multiply `A·µ¢ ‚Ä¶ A‚±º`:

```

Cost(i,j) = min_{k=i}^{j-1} [ Cost(i,k) + Cost(k+1,j) + p_{i-1}¬∑p_k¬∑p_j ]

```

**Base Case:** `Cost(i,i) = 0` (single matrix ‚Äî no multiplication)

- Overlapping subproblems + optimal substructure ‚Üí perfect for DP.

---

### Bottom-Up Dynamic Programming Solution

- Table `m[i][j]` = minimum cost to multiply `A·µ¢ ‚Ä¶ A‚±º`
- Table `s[i][j]` = optimal `k` (last split point) to reconstruct the parenthesization

**Pseudocode (Bottom-Up)**

```

MATRIX-CHAIN-ORDER(p, n)                  // p[0..n] are dimensions
let m[1..n, 1..n] and s[1..n, 1..n] be new tables
for i ‚Üê 1 to n
m[i,i] ‚Üê 0
for l ‚Üê 2 to n                            // l = chain length
for i ‚Üê 1 to n-l+1
j ‚Üê i+l-1
m[i,j] ‚Üê ‚àû
for k ‚Üê i to j-1
q ‚Üê m[i,k] + m[k+1,j] + p[i-1]¬∑p[k]¬∑p[j]
if q < m[i,j]
m[i,j] ‚Üê q
s[i,j] ‚Üê k
return m and s

```

---

### TypeScript Implementation

```ts
/**
 * Matrix Chain Multiplication ‚Äì O(n¬≥) time, O(n¬≤) space
 * Returns minimum cost and optimal parenthesization
 */
function matrixChainOrder(p: number[]): { cost: number; parens: string } {
  const n = p.length - 1; // number of matrices
  const m: number[][] = Array(n + 1)
    .fill(0)
    .map(() => Array(n + 1).fill(0));
  const s: number[][] = Array(n + 1)
    .fill(0)
    .map(() => Array(n + 1).fill(0));

  for (let l = 2; l <= n; l++) {
    // l = chain length
    for (let i = 1; i <= n - l + 1; i++) {
      const j = i + l - 1;
      m[i][j] = Infinity;
      for (let k = i; k <= j - 1; k++) {
        const q = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j];
        if (q < m[i][j]) {
          m[i][j] = q;
          s[i][j] = k;
        }
      }
    }
  }

  // Reconstruct parenthesization
  function printParens(i: number, j: number): string {
    if (i === j) return `A${i}`;
    const k = s[i][j];
    return `(${printParens(i, k)}${printParens(k + 1, j)})`;
  }

  return {
    cost: m[1][n],
    parens: printParens(1, n),
  };
}

// Example (CLRS classic)
const dims = [30, 35, 15, 5, 10, 20, 25]; // A1(30√ó35), ..., A6(20√ó25)
const result = matrixChainOrder(dims);
console.log("Minimum cost:", result.cost); // 26250
console.log("Parenthesization:", result.parens);
```

---

### Important Notes

- **Time complexity:** O(n¬≥) ‚Äî three nested loops
- **Space:** O(n¬≤) ‚Äî can be optimized but not necessary for small `n`
- **Reconstruction:** Extra table `s[i][j]` to rebuild optimal parenthesization

**Real-world applications:**

- Optimizing expression trees
- Query planning in databases
- Tensor contraction order in ML

### Key Takeaway

> Matrix multiplication is associative but cost depends on order. DP finds the optimal parenthesization by solving all subchains bottom-up using optimal substructure.

---

## 14.3 Elements of Dynamic Programming

Dynamic programming works efficiently when a problem has two essential ingredients:

1. **Optimal substructure**
2. **Overlapping subproblems**

These properties allow us to replace exponential-time recursion with polynomial-time solutions.

---

### 1. Optimal Substructure

A problem exhibits optimal substructure if an optimal solution to the problem contains optimal solutions to its subproblems.

**In other words:**

- If the overall optimal solution includes a certain choice, then the remaining part must also be solved optimally.

**Examples:**

- **Rod cutting:** If the optimal way to cut a rod of length `n` starts with a piece of length `i`, the remaining rod of length `n‚àíi` must also be cut optimally.
- **Matrix-chain multiplication:** If the optimal parenthesization of `A‚ÇÅ‚Ä¶A‚Çô` splits after `A‚Çñ`, both subchains `A‚ÇÅ‚Ä¶A‚Çñ` and `A‚Çñ‚Çä‚ÇÅ‚Ä¶A‚Çô` must be parenthesized optimally.

**How to use it:**

```

OPT(n) = optimal value for size n
OPT(n) = max/min over possible first choices { cost + OPT(remaining subproblem) }

```

---

### 2. Overlapping Subproblems

A problem has overlapping subproblems if the same subproblems are solved many times in the recursive solution tree.

- Instead of recomputing, solve each unique subproblem once and store the result (memoization or table).

**Examples:**

- **Rod cutting:** Subproblem for length 4 is solved multiple times when computing larger lengths.
- **Matrix-chain:** Cost of multiplying `A‚ÇÉ‚Ä¶A‚Çá` is needed in many different parenthesizations.

**Key Insight:**

- Without overlapping subproblems ‚Üí memoization/table gives no speedup.
- With overlapping subproblems ‚Üí reduces exponential time to polynomial time (O(n¬≤) or O(n¬≥)).

---

### 3. Two Ways to Build the DP Solution

#### Top-down (memoized recursion)

- Write natural recursive solution.
- Add memoization (store results in array/map).
- Each subproblem computed only once.

#### Bottom-up (iterative tabulation)

- Identify subproblem dependencies.
- Fill table in order from smallest to largest subproblems.
- No recursion stack, usually cleaner and faster.

> Both approaches give identical results ‚Äî only computation order differs.

---

### 4. Comparing Rod Cutting and Matrix-Chain Multiplication

| Property                   | Rod Cutting             | Matrix-Chain Multiplication     |
| -------------------------- | ----------------------- | ------------------------------- |
| Optimal substructure       | Yes                     | Yes                             |
| Overlapping subproblems    | Yes                     | Yes                             |
| Recurrence complexity      | O(n¬≤)                   | O(n¬≥)                           |
| Typical table size         | O(n)                    | O(n¬≤)                           |
| Reconstruction of solution | Extra array s[]         | Extra array s[][]               |
| Real-world analogy         | Cutting rod into pieces | Ordering matrix multiplications |

---

### TypeScript Code ‚Äî Bottom-Up Rod Cutting (with Reconstruction)

```ts
function rodCutting(
  prices: number[],
  n: number,
): { revenue: number; cuts: number[] } {
  const r: number[] = new Array(n + 1);
  const s: number[] = new Array(n + 1); // s[j] = best first cut for length j
  r[0] = 0;

  for (let j = 1; j <= n; j++) {
    let q = -Infinity;
    for (let i = 1; i <= j; i++) {
      if (q < prices[i] + r[j - i]) {
        q = prices[i] + r[j - i];
        s[j] = i;
      }
    }
    r[j] = q;
  }

  // Reconstruct cuts
  const cuts: number[] = [];
  let remaining = n;
  while (remaining > 0) {
    cuts.push(s[remaining]);
    remaining -= s[remaining];
  }

  return { revenue: r[n], cuts };
}

// Example usage
const prices = [0, 1, 5, 8, 9, 10, 17, 17, 20, 24, 30];
const n = 10;
const result = rodCutting(prices, n);
console.log("Max revenue:", result.revenue); // 30
console.log("Cuts:", result.cuts); // e.g. [2,2,6] or [3,3,4]
```

---

### Important Notes

- DP requires **both** optimal substructure and overlapping subproblems.
- Without overlapping subproblems ‚Üí memoization gives no speedup.
- Without optimal substructure ‚Üí greedy approaches may work (see Chapter 15).
- Rod cutting & matrix-chain are textbook examples illustrating these properties.
- Bottom-up is usually preferred in practice (no recursion stack, better cache locality).

### Key Takeaway

> Dynamic programming is powerful when a problem has **optimal substructure** and **overlapping subproblems**, allowing exponential recursion to be replaced by polynomial-time table filling.

---

## 14.4 Longest Common Subsequence

The longest common subsequence (LCS) problem is a classic example of dynamic programming.

### Problem Statement

Given two sequences:

```

X = ‚ü®x‚ÇÅ, x‚ÇÇ, ‚Ä¶, x‚Çò‚ü©
Y = ‚ü®y‚ÇÅ, y‚ÇÇ, ‚Ä¶, y‚Çô‚ü©

```

- A subsequence is obtained by deleting some (or none) elements without changing order.
- A **common subsequence** appears in both X and Y.
- **Longest common subsequence**: the longest such sequence.

**Example:**

```

X = ‚ü®A B C B D A B‚ü©
Y = ‚ü®B D C A B A‚ü©
LCS = ‚ü®B C A B‚ü© (length 4)

```

> There may be multiple LCSs of the same length.

---

### Optimal Substructure

Let `c[i][j]` = length of LCS of `X[1..i]` and `Y[1..j]`

**Recurrence:**

```

c[i,j] = 0                      if i=0 or j=0
c[i,j] = c[i-1,j-1] + 1         if x_i = y_j
c[i,j] = max(c[i-1,j], c[i,j-1]) otherwise

```

- Has optimal substructure and overlapping subproblems ‚Üí perfect for DP.

---

### Bottom-Up Dynamic Programming Solution

- Fill table `c[0..m][0..n]` bottom-up.
- Keep table `b[i][j]` = direction arrow to reconstruct one actual LCS.

**Pseudocode:**

```

LCS-LENGTH(X, Y)
m ‚Üê length[X]
n ‚Üê length[Y]
let c[0..m, 0..n] and b[1..m, 1..n] be new tables

```

for i ‚Üê 0 to m
c[i,0] ‚Üê 0
for j ‚Üê 0 to n
c[0,j] ‚Üê 0

for i ‚Üê 1 to m
for j ‚Üê 1 to n
if x_i = y_j
c[i,j] ‚Üê c[i-1,j-1] + 1
b[i,j] ‚Üê '‚Üñ'
else if c[i-1,j] ‚â• c[i,j-1]
c[i,j] ‚Üê c[i-1,j]
b[i,j] ‚Üê '‚Üë'
else
c[i,j] ‚Üê c[i,j-1]
b[i,j] ‚Üê '‚Üê'

return c and b

```

**Reconstruct LCS (using arrows in `b`)**
```

PRINT-LCS(b, X, i, j)
if i = 0 or j = 0 return
if b[i,j] = '‚Üñ'
PRINT-LCS(b, X, i-1, j-1)
print x_i
else if b[i,j] = '‚Üë'
PRINT-LCS(b, X, i-1, j)
else
PRINT-LCS(b, X, i, j-1)

````

---

### TypeScript Implementation
```ts
/**
 * Longest Common Subsequence ‚Äì O(mn) time, O(mn) space
 * Returns LCS length and one possible LCS string
 */
function longestCommonSubsequence(X: string, Y: string): { length: number; lcs: string } {
    const m = X.length;
    const n = Y.length;

    const c: number[][] = Array(m + 1).fill(0).map(() => Array(n + 1).fill(0));
    const b: string[][] = Array(m + 1).fill(0).map(() => Array(n + 1).fill(''));

    for (let i = 1; i <= m; i++) {
        for (let j = 1; j <= n; j++) {
            if (X[i - 1] === Y[j - 1]) {
                c[i][j] = c[i - 1][j - 1] + 1;
                b[i][j] = '‚Üñ';
            } else if (c[i - 1][j] >= c[i][j - 1]) {
                c[i][j] = c[i - 1][j];
                b[i][j] = '‚Üë';
            } else {
                c[i][j] = c[i][j - 1];
                b[i][j] = '‚Üê';
            }
        }
    }

    function buildLCS(i: number, j: number): string {
        if (i === 0 || j === 0) return '';
        if (b[i][j] === '‚Üñ') return buildLCS(i - 1, j - 1) + X[i - 1];
        if (b[i][j] === '‚Üë') return buildLCS(i - 1, j);
        return buildLCS(i, j - 1);
    }

    return {
        length: c[m][n],
        lcs: buildLCS(m, n)
    };
}

// Example usage
const X = 'ABCBDAB';
const Y = 'BDCAB';
const result = longestCommonSubsequence(X, Y);
console.log('LCS length:', result.length);   // 4
console.log('One LCS:', result.lcs);         // e.g. 'BCAB' or 'BDAB'
````

---

### Important Notes

- **Time complexity:** O(mn)
- **Space complexity:** O(mn) (can be optimized to O(min(m,n)))
- Reconstructing the actual subsequence needs extra bookkeeping (`b` table)
- Widely used: DNA alignment, diff tools, plagiarism detection, version control, spell checking
- Multiple LCSs may exist ‚Äî algorithm returns one of them

### Key Takeaway

> LCS demonstrates optimal substructure and overlapping subproblems. Solve bottom-up by filling table `c[i][j]` representing LCS length for prefixes of X and Y.

---

## 14.5 Optimal Binary Search Trees

The **optimal binary search tree (OBST)** problem is a classic dynamic programming application.

### Problem Setup

Given:

- `n` distinct keys `k‚ÇÅ < k‚ÇÇ < ‚Ä¶ < k‚Çô`
- Probability `p·µ¢` that key `k·µ¢` is searched
- Probability `q·µ¢` that a search is made for a value between `k·µ¢` and `k·µ¢‚Çä‚ÇÅ` (dummy keys)

**Goal:** Build a BST that **minimizes expected search cost** (weighted path length).

### Expected Search Cost

For BST with root `r`, left subtree `L`, right subtree `R`:

```

Expected cost = p·µ£ + (1 + expected cost of L) + (1 + expected cost of R)
= 1 + expected cost of L + expected cost of R + sum of probabilities in L and R

```

> Every search goes through the root (+1), all probabilities in the subtree increase by 1.

---

### Optimal Substructure

Let `e[i,j]` = minimum expected search cost for keys `k·µ¢ ‚Ä¶ k‚±º` with dummy probabilities `q_{i-1} ‚Ä¶ q‚±º`

**Recurrence:**

```

e[i,j] = ‚àû if i > j

e[i,i-1] = q_{i-1}  // empty tree

e[i,j] = min_{r=i..j} [ e[i,r-1] + e[r+1,j] + w(i,j) ]

w(i,j) = sum_{l=i..j} p_l + sum_{l=i-1..j} q_l  // total probability in subtree

```

- `+w(i,j)` accounts for +1 cost at every subtree level.

---

### Bottom-Up Dynamic Programming Solution

- Fill table `e[1..n+1][0..n]`
- Keep table `root[i][j]` = optimal root for subtree `i..j`

**Pseudocode:**

```

OPTIMAL-BST(p, q, n)
let e[1..n+1,0..n], w[1..n+1,0..n], root[1..n,1..n] be new tables

```

for i = 1 to n+1
e[i,i-1] = q[i-1]
w[i,i-1] = q[i-1]

for l = 1 to n // chain length
for i = 1 to n-l+1
j = i+l-1
e[i,j] = ‚àû
w[i,j] = w[i,j-1] + p[j] + q[j]
for r = i to j
t = e[i,r-1] + e[r+1,j] + w[i,j]
if t < e[i,j]
e[i,j] = t
root[i,j] = r

return e and root

```

```

---

### TypeScript Implementation

```ts
/**
 * Optimal BST ‚Äì O(n¬≥) time, O(n¬≤) space
 * Returns minimum expected cost and root table
 */
function optimalBST(
  p: number[],
  q: number[],
  n: number,
): { cost: number; root: number[][] } {
  const e: number[][] = Array(n + 2)
    .fill(0)
    .map(() => Array(n + 1).fill(0));
  const w: number[][] = Array(n + 2)
    .fill(0)
    .map(() => Array(n + 1).fill(0));
  const rootTable: number[][] = Array(n + 1)
    .fill(0)
    .map(() => Array(n + 1).fill(0));

  // Initialize
  for (let i = 1; i <= n + 1; i++) {
    e[i][i - 1] = q[i - 1];
    w[i][i - 1] = q[i - 1];
  }

  // Fill table by chain length l
  for (let l = 1; l <= n; l++) {
    for (let i = 1; i <= n - l + 1; i++) {
      const j = i + l - 1;
      e[i][j] = Infinity;
      w[i][j] = w[i][j - 1] + p[j] + q[j];

      for (let r = i; r <= j; r++) {
        const t = e[i][r - 1] + e[r + 1][j] + w[i][j];
        if (t < e[i][j]) {
          e[i][j] = t;
          rootTable[i][j] = r;
        }
      }
    }
  }

  return { cost: e[1][n], root: rootTable };
}

// Helper: reconstruct tree structure
function buildTreeFromRoot(
  rootTable: number[][],
  i: number,
  j: number,
): { node: number; left?: any; right?: any } | null {
  if (i > j) return null;
  const r = rootTable[i][j];
  return {
    node: r,
    left: buildTreeFromRoot(rootTable, i, r - 1),
    right: buildTreeFromRoot(rootTable, r + 1, j),
  };
}

// Example usage
const p = [0, 0.15, 0.1, 0.05, 0.1, 0.2]; // keys 1..5
const q = [0.05, 0.1, 0.05, 0.05, 0.05, 0.1]; // dummies 0..5

const result = optimalBST(p, q, 5);
console.log("Minimum expected cost:", result.cost.toFixed(3)); // ~2.75
const treeStructure = buildTreeFromRoot(result.root, 1, 5);
console.log("Optimal tree structure:", JSON.stringify(treeStructure, null, 2));
```

---

### Important Notes

- **Time complexity:** O(n¬≥) ‚Äî three nested loops
- **Space complexity:** O(n¬≤) ‚Äî slight optimizations possible
- Extra table `root[i][j]` allows reconstructing optimal tree structure
- Minimizes expected search cost when access probabilities are known
- Real-world use: static search tables, compilers, databases, keyboard layouts

### Key Takeaway

> OBSTs are built with DP by minimizing expected search cost over all roots. The recurrence exploits optimal substructure and overlapping subproblems.
