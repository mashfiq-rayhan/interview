# 2. Getting Started

## ğŸ“‹ Chapter Overview

| Section | Topic                | Key Idea                                 |
| ------- | -------------------- | ---------------------------------------- |
| **2.1** | Insertion sort       | Simple, in-place, great for small inputs |
| **2.2** | Analyzing algorithms | Machine-independent cost model           |
| **2.3** | Designing algorithms | Divide-and-conquer via merge sort        |

---

## 2.1 Insertion Sort

### What is insertion sort?

Insertion sort is one of the simplest sorting algorithms. It mirrors how people usually sort playing cards in their hands and performs extremely well on **small** or **nearly sorted** datasets.

The algorithm builds the sorted array **one element at a time**.

### Intuition (in plain words)

1. The first element is already sorted.
2. Take the next element (called the **key**).
3. Compare the key with elements in the sorted portion (right â†’ left).
4. Shift all larger elements one position to the right.
5. Insert the key in its correct position.

### Pseudocode (CLRS â€“ 1â€‘based indexing)

```text
INSERTION-SORT(A, n)
    for i = 2 to n
        key â† A[i]
        j â† i - 1
        while j > 0 and A[j] > key
            A[j + 1] â† A[j]
            j â† j - 1
        A[j + 1] â† key
```

### TypeScript implementation (0â€‘based indexing)

```ts
function insertionSort(A: number[]): number[] {
  const n = A.length;

  for (let i = 1; i < n; i++) {
    const key = A[i];
    let j = i - 1;

    while (j >= 0 && A[j] > key) {
      A[j + 1] = A[j];
      j--;
    }

    A[j + 1] = key;
  }

  return A;
}
```

### Stepâ€‘byâ€‘step example

Initial array:

```
[31, 41, 59, 26, 41, 58]
```

```
i = 1 â†’ key = 41 â†’ already sorted
[31, 41, 59, 26, 41, 58]

i = 2 â†’ key = 59 â†’ already sorted
[31, 41, 59, 26, 41, 58]

i = 3 â†’ key = 26 â†’ shift 59, 41, 31
[26, 31, 41, 59, 41, 58]

i = 4 â†’ key = 41 â†’ shift 59
[26, 31, 41, 41, 59, 58]

i = 5 â†’ key = 58 â†’ shift 59
[26, 31, 41, 41, 58, 59]
```

Final result:

```
[26, 31, 41, 41, 58, 59]
```

### Key properties

| Property          | Value | Notes                       |
| ----------------- | ----- | --------------------------- |
| Bestâ€‘case time    | Î˜(n)  | Already sorted              |
| Averageâ€‘case time | Î˜(nÂ²) | Random order                |
| Worstâ€‘case time   | Î˜(nÂ²) | Reverse sorted              |
| Space             | Î˜(1)  | Inâ€‘place                    |
| Stable            | Yes   | Relative order preserved    |
| Adaptive          | Yes   | Fast on nearly sorted input |

### When should you use insertion sort?

- Small arrays (â‰ˆ 50â€“100 elements)
- Nearly sorted data
- Base case for hybrid algorithms (Timsort, Introsort)
- Situations where simplicity and low overhead matter

### Summary

- Insertion sort is **simple, intuitive, and inâ€‘place**
- Excellent on **small or nearly sorted** data
- Quadratic in average/worst cases â†’ not for large random inputs
- Ideal teaching algorithm for understanding correctness and analysis

### Exercises

> 2.1â€‘1 Illustrate INSERTION-SORT on âŸ¨31, 41, 59, 26, 41, 58âŸ©.

```ts
function insertionSort(A: number[]): void {
  const n = A.length;
  for (let i = 1; i < n; i++) {
    const key = A[i];
    let j = i - 1;
    while (j >= 0 && A[j] > key) {
      A[j + 1] = A[j];
      j--;
    }
    A[j + 1] = key;
  }
}

const ex1 = [31, 41, 59, 26, 41, 58];
insertionSort(ex1);
console.log("2.1-1:", ex1);
```

> 2.1â€‘2 Loop invariant (SUMâ€‘ARRAY)

```ts
function sumArray(A: number[]): number {
  let sum = 0;
  for (let i = 0; i < A.length; i++) {
    sum += A[i];
  }
  return sum;
}

console.log("2.1-2:", sumArray([1, 2, 3, 4, 5]));
```

> 2.1â€‘3 Decreasing order insertion sort

```ts
function reverseInsertionSort(A: number[]): number[] {
  const n = A.length;

  for (let i = 1; i < n; i++) {
    const key = A[i];
    let j = i - 1;

    while (j >= 0 && A[j] < key) {
      A[j + 1] = A[j];
      j--;
    }

    A[j + 1] = key;
  }

  return A;
}
```

> 2.1â€‘4 Linear search

```ts
function linearSearch(A: number[], x: number): number | null {
  for (let i = 0; i < A.length; i++) {
    if (A[i] === x) return i;
  }
  return null;
}
```

> 2.1â€‘5 Binary addition

```ts
function addBinary(A: number[], B: number[]): number[] {
  const n = A.length;
  const C = new Array(n + 1).fill(0);
  let carry = 0;

  for (let i = n - 1; i >= 0; i--) {
    const sum = A[i] + B[i] + carry;
    C[i + 1] = sum % 2;
    carry = Math.floor(sum / 2);
  }

  C[0] = carry;
  return C;
}
```

---

## 2.2 Analyzing Algorithms

### Why we donâ€™t measure time in seconds

Real execution time depends on hardware, OS, compiler, and language. To compare algorithms meaningfully, we use a **machineâ€‘independent** approach that focuses on how performance **scales with input size n**.

### The RAM Model (CLRS)

- Each **basic operation** costs constant time
- Examples: arithmetic, comparisons, assignments, array access
- Not realisticâ€”but extremely useful for analysis

### Insertion Sort Analysis (worst case)

**Worst case:** input is reverse sorted.

**Observation:** For each `i`, the inner `while` loop runs `iâˆ’1` times.

**Total work:**
[(nâˆ’1) + (nâˆ’2) + \dots + 1 = \frac{n(nâˆ’1)}{2} = Î˜(n^2)]

Therefore:

- **Worst case:** Î˜(nÂ²)
- **Average case:** Î˜(nÂ²)
- **Best case (already sorted):** Î˜(n)

### Reference Implementation (0â€‘based indexing)

```ts
function insertionSort(A: number[]): number[] {
  const n = A.length;
  for (let i = 1; i < n; i++) {
    const key = A[i];
    let j = i - 1;
    while (j >= 0 && A[j] > key) {
      A[j + 1] = A[j];
      j--;
    }
    A[j + 1] = key;
  }
  return A;
}
```

### Case Analysis Summary

| Case    | Input Order    | Running Time |
| ------- | -------------- | ------------ |
| Best    | Already sorted | Î˜(n)         |
| Average | Random         | Î˜(nÂ²)        |
| Worst   | Reverse sorted | Î˜(nÂ²)        |

### Key Takeaways

- We care about **asymptotic growth**, not constants
- Quadratic algorithms become infeasible quickly
- Worstâ€‘case analysis provides a performance guarantee
- Asymptotic notation lets us compare algorithms cleanly

### Practical Intuition

| n         | Î˜(n)      | Î˜(nÂ²)             |
| --------- | --------- | ----------------- |
| 10        | 10        | 100               |
| 100       | 100       | 10,000            |
| 1,000     | 1,000     | 1,000,000         |
| 1,000,000 | 1,000,000 | 1,000,000,000,000 |

**Bottom line:** choosing the right algorithm usually matters far more than faster hardware.

---

## 2.3 Designing Algorithms

Section 2.3 shows how we can **systematically design better algorithms** than simple insertion sort (Section 2.1). The central idea introduced here is a powerful and widely applicable algorithm design paradigm: **divide-and-conquer**.

### 1. The Divide-and-Conquer Paradigm

Most efficient algorithms follow this three-step pattern:

1. **Divide** â€” Break the problem into smaller subproblems of the same type.
2. **Conquer** â€” Solve the subproblems recursively (if small enough, solve directly).
3. **Combine** â€” Combine the solutions of the subproblems to obtain a solution to the original problem.

This paradigm appears throughout computer science: sorting, searching, matrix multiplication, FFTs, and many geometric algorithms.

### 2. Classic Example: Merge Sort

#### Idea (in simple words)

- Split the array into two halves.
- Recursively sort each half.
- Merge the two already sorted halves into one sorted array.

#### Pseudocode â€” MERGE-SORT (CLRS style, 1-based indexing)

```ts
MERGE-SORT(A, p, r)
    if p â‰¥ r                        // 0 or 1 element â†’ already sorted
        return
    q â† âŒŠ(p + r)/2âŒ‹                 // calculate midpoint
    MERGE-SORT(A, p, q)             // sort left half
    MERGE-SORT(A, q + 1, r)         // sort right half
    MERGE(A, p, q, r)               // merge both halves
```

```ts
MERGE(A, p, q, r)
    nâ‚ â† q âˆ’ p + 1
    nâ‚‚ â† r âˆ’ q
    create temporary arrays L[1..nâ‚ + 1] and R[1..nâ‚‚ + 1]

    for i â† 1 to nâ‚
        L[i] â† A[p + i âˆ’ 1]
    for j â† 1 to nâ‚‚
        R[j] â† A[q + j]

    L[nâ‚ + 1] â† âˆ                   // sentinel
    R[nâ‚‚ + 1] â† âˆ                   // sentinel

    i â† 1, j â† 1

    for k â† p to r
        if L[i] â‰¤ R[j]
            A[k] â† L[i]
            i â† i + 1
        else
            A[k] â† R[j]
            j â† j + 1
```

The **sentinel values (âˆ)** simplify the merge logic by avoiding explicit boundary checks.

#### Visual Summary of Recursion

```
                            [38,27,43,3,9,82,10]
                          /                      \
                [38,27,43,3]                       [9,82,10]
              /           \                        /         \
       [38,27]         [43,3]                   [9]       [82,10]
      /     \          /   \                             /    \
   [38]   [27]     [43]   [3]                         [82]   [10]


            [27,38]      [3,43]            [9]        [10,82]
                \         /                  \          /
                  [3,27,38,43]                 [9,10,82]
                          \                      /
                            [3,9,10,27,38,43,82]
```

#### TypeScript Implementation (0-based, clean & practical)

```ts
function mergeSort(A: number[], start = 0, end = A.length - 1): void {
  if (start >= end) return;

  const mid = Math.floor((start + end) / 2);

  // Divide
  mergeSort(A, start, mid);
  mergeSort(A, mid + 1, end);

  // Conquer + Combine
  merge(A, start, mid, end);
}

function merge(A: number[], start: number, mid: number, end: number): void {
  const n1 = mid - start + 1;
  const n2 = end - mid;

  // Create temporary arrays
  const L = new Array<number>(n1);
  const R = new Array<number>(n2);

  // Copy data to temporary arrays
  for (let i = 0; i < n1; i++) {
    L[i] = A[start + i];
  }
  for (let j = 0; j < n2; j++) {
    R[j] = A[mid + 1 + j];
  }

  let i = 0; // index for L
  let j = 0; // index for R
  let k = start; // index for merged result in A

  // Merge the two halves back into A
  while (i < n1 && j < n2) {
    if (L[i] <= R[j]) {
      A[k] = L[i];
      i++;
    } else {
      A[k] = R[j];
      j++;
    }
    k++;
  }

  // Copy remaining elements of L (if any)
  while (i < n1) {
    A[k] = L[i];
    i++;
    k++;
  }

  // Copy remaining elements of R (if any)
  while (j < n2) {
    A[k] = R[j];
    j++;
    k++;
  }
}

// Example usage
const arr = [38, 27, 43, 3, 9, 82, 10];
console.log("Before:", arr);
mergeSort(arr);
console.log("After: ", arr);
```

### 3. Why Merge Sort Is Much Better Than Insertion Sort

| Input size (n) | Insertion Sort (worst case) | Merge Sort  | Approximate speedup |
| -------------- | --------------------------- | ----------- | ------------------- |
| 10             | ~100 operations             | ~100        | 1Ã—                  |
| 100            | ~10,000                     | ~1,000      | 10Ã—                 |
| 1,000          | ~1,000,000                  | ~10,000     | 100Ã—                |
| 1,000,000      | ~10Â¹Â²                       | ~20 million | ~50,000Ã—            |

**Conclusion:** for large inputs, merge sort is dramatically faster.

### 4. First Intuition About Running Time

Merge sortâ€™s running time is captured by the recurrence:

[
T(n) = 2T(n/2) + Î˜(n)
]

- Two recursive calls on subproblems of size _n/2_.
- Linear work to merge the two halves.

This recurrence solves to:

[
T(n) = Î˜(n \log n)
]

A detailed solution method is presented in **Chapter 4 (Divide-and-Conquer Analysis)**.

### 5. Key Lessons from Section 2.3

- There exist much faster algorithms than insertion sort for the same problem.
- Divide-and-conquer is one of the most powerful algorithm design techniques.
- Different algorithms exhibit radically different **scaling behavior**.
- Choosing the right algorithm can transform a problem from impractical to efficient.
