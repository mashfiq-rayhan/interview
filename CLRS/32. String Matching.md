# 32. String Matching

## ğŸ“‹ Chapter Overview

- Naive string matching
- More advanced exact matching algorithms (e.g., Rabinâ€“Karp, KMP, automata-based)
- Text indexing data structures for fast pattern queries

---

## 32.1 The naive string-matching algorithm

This section presents the simplest and most straightforward approach to the string-matching problem â€” finding all occurrences of a pattern string \(P\) of length \(m\) inside a text string \(T\) of length \(n\).

### Core Idea

The naive algorithm works exactly like how a human would search for a word in a book:

- Try to match \(P\) starting at every possible position in \(T\) (from position 0 to \(n - m\)).
- For each starting position \(s\) in \(T\), compare characters one by one:
  - \(P[1..m]\) against \(T[s+1..s+m]\).
- If all characters match â†’ report position \(s\).
- If any character mismatches â†’ move to the next starting position.

This is extremely easy to understand and implement, but it is inefficient in the worst case.

### Time complexity

- **Best case:** \(\Theta(n + m)\) â€” when almost no matches occur.
- **Worst case:** \(\Theta(nm)\) â€” when many partial matches happen.
- **Classic worst-case example:**
  - \(T = \text{"aaaaaaaaaaâ€¦aaa"}\) (\(n\) a's)
  - \(P = \text{"aaaaaaaab"}\) (\(mâˆ’1\) a's followed by `b`)
  - Almost every starting position compares \(mâˆ’1\) characters before failing.

Despite the poor worst-case time, the naive algorithm is still useful in practice for small patterns or when mismatches happen early on average.

### Pseudocode

```text
NAIVE-STRING-MATCHER(T, P)
    n â† length[T]
    m â† length[P]

    for s â† 0 to n âˆ’ m
        if P[1..m] matches T[s+1..s+m]
            print "Pattern occurs at shift" s

// Check match (inner comparison)
for j â† 1 to m
    if T[s+j] â‰  P[j]
        break (go to next s)
    if j reached m
        match found at s
```

### TypeScript â€“ naive string matching

```ts
/**
 * Naive string matching â€“ finds all starting positions where pattern appears in text
 * @param text - the longer string to search in
 * @param pattern - the substring to find
 * @returns array of starting indices where pattern occurs in text
 */
function naiveStringMatch(text: string, pattern: string): number[] {
  const n = text.length;
  const m = pattern.length;
  const occurrences: number[] = [];

  if (m === 0) return []; // empty pattern
  if (n < m) return []; // pattern longer than text

  // Try every possible starting position
  for (let s = 0; s <= n - m; s++) {
    let j = 0;

    // Compare characters one by one
    while (j < m && text[s + j] === pattern[j]) {
      j++;
    }

    // If we matched the entire pattern
    if (j === m) {
      occurrences.push(s);
    }
  }

  return occurrences;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const text = "ABABDABACDABABCABAB";
const pattern = "ABABCABAB";

console.log("Text:    ", text);
console.log("Pattern: ", pattern);

const positions = naiveStringMatch(text, pattern);

console.log("Pattern occurs at starting positions:", positions);
// Expected output: [10]  (0-based index)

console.log("\nAll occurrences:");
positions.forEach((pos) => {
  console.log(`Position ${pos}: ${text.slice(pos, pos + pattern.length)}`);
});

// Another example â€“ worst case style
const longA = "a".repeat(100);
const patternAlmost = "a".repeat(99) + "b";

console.log("\nWorst-case style:");
const worstPositions = naiveStringMatch(longA, patternAlmost);
console.log("Occurrences:", worstPositions); // []
```

### Important Notes

- Time complexity: \(\Theta((nâˆ’m+1)Â·m)\) in worst case â†’ \(\Theta(nm)\).
- Best/average case much better if mismatches happen early.
- Very easy to implement â†’ often used as baseline or when \(m\) is small.
- No preprocessing of pattern or text required.
- Suffers badly when pattern and text share many long prefixes (e.g., many `a`'s).
- The algorithms in the rest of Chapter 32 (Rabinâ€“Karp, KMP, etc.) are designed to avoid this worst-case quadratic behavior.

### ğŸ“ Key Takeaway

The naive string-matching algorithm tries to match the pattern \(P\) at every possible starting position in the text \(T\) by comparing characters one by one. It is extremely simple and requires no preprocessing, but has a worst-case running time of \(\Theta(nm)\).

---

## 32.2 The Rabinâ€“Karp algorithm

The Rabinâ€“Karp algorithm is a fast and elegant string-matching method that uses hashing to avoid unnecessary character-by-character comparisons most of the time. It achieves the same \(\Theta(n + m)\) average-case time complexity as KMP or Boyerâ€“Moore, but with a simpler idea and good practical constant factors in many cases.

### Core Idea

Instead of comparing the pattern \(P\) directly with every substring \(T[s+1..s+m]\):

- Precompute a hash value of the pattern \(P\).
- Compute rolling hash values for every substring of \(T\) of length \(m\).
- Only when the hash values match do we perform the actual character-by-character comparison to confirm.

Because comparing hash values is \(O(1)\), most positions are rejected very quickly. The actual string comparison only happens on very few candidate positions. With a good hash function, spurious hits (hash collision but strings are different) are extremely rare.

### Rolling hash â€“ the key trick

- Treat strings as large numbers in base \(d\) (usually \(d = 256\) for ASCII or larger).
- Example: pattern `abc` with \(d = 256\)
  - \(\text{value} = aÂ·256^2 + bÂ·256^1 + cÂ·256^0\).
- Compute the hash value of the first window \(T[1..m]\).
- For each next position \(s+1\), compute the next hash in \(O(1)\) time using the rolling hash formula:

$$h_{s+1} = (h_s âˆ’ T[s+1]Â·d^{m-1})Â·d + T[s+m] \pmod q$$

This removes the leftmost character and adds the new rightmost character â€” very fast. We choose a large prime modulus \(q\) to reduce collisions.

### Pseudocode

```text
RABIN-KARP-MATCHER(T, P, d, q)
// T = text, P = pattern, d = radix (usually 256), q = large prime modulus
n â† length[T]
m â† length[P]

if m = 0 return

// Precompute highest power: d^{m-1} mod q
h â† d^{m-1} mod q

// Compute hash of pattern
pHash â† 0
for i â† 1 to m
    pHash â† (d Â· pHash + P[i]) mod q

// Compute hash of first window of text
tHash â† 0
for i â† 1 to m
    tHash â† (d Â· tHash + T[i]) mod q

for s â† 0 to n âˆ’ m
    if pHash = tHash
        if P[1..m] exactly matches T[s+1..s+m]
            report match at position s

    if s < n âˆ’ m
        // Roll the hash forward
        tHash â† (d Â· (tHash âˆ’ T[s+1] Â· h) + T[s+m+1]) mod q
        if tHash < 0 then tHash â† tHash + q
```

### TypeScript â€“ Rabinâ€“Karp string matching

```ts
/**
 * Rabin-Karp string matching using rolling hash
 * @param text - text to search in
 * @param pattern - pattern to find
 * @param radix - base (usually 256 or 128)
 * @param prime - large prime modulus (should be large enough to reduce collisions)
 * @returns array of starting indices (0-based) where pattern occurs
 */
function rabinKarp(
  text: string,
  pattern: string,
  radix: number = 256,
  prime: number = 1000000007,
): number[] {
  const n = text.length;
  const m = pattern.length;
  const occurrences: number[] = [];

  if (m === 0 || n < m) return occurrences;

  // Precompute highest power: radix^(m-1) % prime
  let highestPower = 1;
  for (let i = 1; i <= m - 1; i++) {
    highestPower = (highestPower * radix) % prime;
  }

  // Hash of pattern
  let patternHash = 0;
  for (let i = 0; i < m; i++) {
    patternHash = (patternHash * radix + pattern.charCodeAt(i)) % prime;
  }

  // Hash of first window of text
  let textHash = 0;
  for (let i = 0; i < m; i++) {
    textHash = (textHash * radix + text.charCodeAt(i)) % prime;
  }

  for (let s = 0; s <= n - m; s++) {
    // Hash match â†’ verify with actual comparison
    if (patternHash === textHash) {
      let matched = true;
      for (let j = 0; j < m; j++) {
        if (text[s + j] !== pattern[j]) {
          matched = false;
          break;
        }
      }
      if (matched) {
        occurrences.push(s);
      }
    }

    // Roll hash to next window (if not last position)
    if (s < n - m) {
      textHash =
        (radix * (textHash - text.charCodeAt(s) * highestPower) +
          text.charCodeAt(s + m)) %
        prime;

      // Handle negative values
      if (textHash < 0) {
        textHash += prime;
      }
    }
  }

  return occurrences;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const text = "ABABDABACDABABCABAB";
const pattern = "ABABCABAB";

console.log("Text:    ", text);
console.log("Pattern: ", pattern);

const positions = rabinKarp(text, pattern);

console.log("Pattern occurs at starting positions:", positions);
// Expected: [10]

console.log("\nAll occurrences:");
positions.forEach((pos) => {
  console.log(`Position ${pos}: ${text.slice(pos, pos + pattern.length)}`);
});

// Worst-case style test
const longA = "a".repeat(1000);
const almostPattern = "a".repeat(999) + "b";

console.log("\nRabin-Karp on almost-matching case:");
const posWorst = rabinKarp(longA, almostPattern);
console.log("Occurrences:", posWorst); // should be [] and fast
```

### Important Notes

- Average-case running time is \(\Theta(n + m)\) â€” excellent in practice.
- Worst-case time is still \(\Theta(nm)\) â€” when there are many hash collisions.
- Choosing a large prime \(q\) and good radix reduces collisions dramatically.
- Double hashing (two independent hashes) makes collisions extremely unlikely.
- Particularly useful when:
  - we want to find multiple patterns (just hash all patterns first),
  - we are working with binary data or very long patterns,
  - we need a simple, easy-to-implement algorithm with good average performance.

### ğŸ“ Key Takeaway

Rabinâ€“Karp uses rolling hashes to quickly filter out positions where the pattern cannot match, and only performs full string comparison on hash matches, giving \(\Theta(n + m)\) expected time.

---

## 32.3 String Matching with Finite Automata

This section presents a powerful and general framework for string matching: using a finite automaton (specifically a deterministic finite automaton, DFA) to recognize all occurrences of a pattern in a text. The approach is conceptually elegant and is the theoretical foundation for several efficient string-matching algorithms (including KMP).

### Core Idea

We build a finite automaton that â€œrecognizesâ€ the pattern \(P\):

- The states of the automaton represent how much of the pattern we have matched so far (state \(k\) means we have already matched the first \(k\) characters of \(P\)).
- State 0 = no prefix matched yet.
- State \(m\) = full pattern matched (accepting state).

As we read each character of the text \(T\), we transition between states according to the next character. Whenever we reach state \(m\), we have found an occurrence of \(P\) ending at the current position in \(T\).

### Key components

- **Transition function** \(\delta(q, a)\)
  - \(q\) = current state (0 to \(m\)).
  - \(a\) = next character from text.
  - \(\delta(q, a)\) = length of the longest prefix of \(P\) that is a suffix of the string formed by the characters seen so far after reading \(a\).
- The automaton is deterministic â€” for each state and each possible character there is exactly one next state.
- We precompute the transition table \(\delta\) once per pattern.

### Time complexity

- **Preprocessing (building \(\delta\))**: \(O(m |\Sigma|)\), where \(\Sigma\) is the alphabet.
- **Matching phase**: \(O(n)\) â€” exactly one transition per character of the text.
- **Total**: \(O(m |\Sigma| + n)\).

### Pseudocode

```text
FINITE-AUTOMATON-MATCHER(T, Î´, m)
    q â† 0                        // start in state 0

    for i â† 1 to n               // for each character in text
        q â† Î´(q, T[i])           // transition

        if q = m                 // reached accepting state
            print "Pattern occurs with shift" i âˆ’ m

COMPUTE-TRANSITION-FUNCTION(P, Î£)
    m â† length[P]

    let Î´[0..m, Î£] be new table

    for each state q â† 0 to m
        for each character a âˆˆ Î£
            k â† min(m, q + 1)          // optimistic guess: we matched one more

            while k > 0 and P[k] â‰  a   // find longest proper prefix that is suffix
                k â† longest prefix of P[1..k-1] that is suffix of P[1..k-1] + a

            Î´[q, a] â† k
```

### TypeScript â€“ finite automaton string matching

```ts
/**
 * Builds the transition table Î´ for the finite automaton
 * @param pattern - pattern string P
 * @param alphabet - set of characters (simplified: we assume ASCII or input string chars)
 */
function computeTransitionFunction(
  pattern: string,
): Map<number, Map<string, number>> {
  const m = pattern.length;
  const delta = new Map<number, Map<string, number>>();

  // For each possible state 0 to m
  for (let q = 0; q <= m; q++) {
    delta.set(q, new Map<string, number>());

    // Minimal alphabet for demo: characters from pattern
    const chars = new Set([...pattern]);

    for (const char of chars) {
      let k = Math.min(m, q + 1);

      // Find longest prefix that is suffix after adding char
      while (k > 0 && pattern[k - 1] !== char) {
        k--;
      }

      delta.get(q)!.set(char, k);
    }
  }

  return delta;
}

/**
 * Finite automaton string matcher
 * @param text - text to search in
 * @param pattern - pattern to find
 * @returns array of starting positions (0-based) where pattern occurs
 */
function finiteAutomatonStringMatch(text: string, pattern: string): number[] {
  if (pattern.length === 0) return [];

  const m = pattern.length;
  const n = text.length;
  const occurrences: number[] = [];

  const delta = computeTransitionFunction(pattern);

  let q = 0; // current state

  for (let i = 0; i < n; i++) {
    const char = text[i];

    // Transition (use pattern chars or fallback to 0 if char not in transition)
    const trans = delta.get(q)!;
    q = trans.has(char) ? trans.get(char)! : 0;

    if (q === m) {
      occurrences.push(i - m + 1); // starting position (0-based)
      // Optional: continue searching for overlapping matches
      q = trans.get(pattern[m - 1]) || 0; // stay or go back
    }
  }

  return occurrences;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const text = "ABABDABACDABABCABAB";
const pattern = "ABABCABAB";

console.log("Text:    ", text);
console.log("Pattern: ", pattern);

const positions = finiteAutomatonStringMatch(text, pattern);

console.log("Pattern occurs at starting positions (0-based):", positions);
// Expected: [10]

console.log("\nAll occurrences:");
positions.forEach((pos) => {
  console.log(`Position ${pos}: ${text.slice(pos, pos + pattern.length)}`);
});
```

### Important Notes

- Time complexity: \(O(m |\Sigma|)\) preprocessing + \(O(n)\) matching.
- The automaton is deterministic â€” one transition per character.
- Handles overlapping matches naturally.
- Building the full transition table is expensive when \(|\Sigma|\) is large.
- This framework underlies KMP, which avoids explicitly building \(\delta\) by using the prefix function.

### ğŸ“ Key Takeaway

String matching can be elegantly modeled using a DFA whose states represent the length of the current matched prefix of the pattern. The automaton runs once on the text, making exactly one transition per character.

---

## 32.4 The Knuthâ€“Morrisâ€“Pratt (KMP) Algorithm

The Knuthâ€“Morrisâ€“Pratt (KMP) algorithm avoids the quadratic worst-case time of the naive method by never backtracking in the text and by preprocessing the pattern to skip unnecessary comparisons.

### Core Idea

When a mismatch occurs while matching the pattern \(P\) against the text \(T\) at position \(s\):

- Instead of shifting the pattern by just 1 position (like naive), we use information about how much prefix of \(P\) is already matched and how much of that prefix overlaps with the suffix of what we have just seen.
- This allows us to shift the pattern by more than 1 position safely â€” often by many characters at once.

The key data structure is the **prefix function** (failure function / border array) \(\pi\):

- \(\pi[q]\) = length of the longest proper prefix of \(P[0..q]\) that is also a suffix of \(P[0..q]\).
- This value tells us how far we can safely shift the pattern after a mismatch.

### Two phases

- **Preprocessing** â€” compute the prefix table \(\pi\) for the pattern \(P\) in \(\Theta(m)\) time.
- **Matching** â€” run the automaton on the text \(T\) using \(\pi\) to guide transitions in \(\Theta(n)\) time.

Total running time is \(\Theta(n + m)\) in the worst case.

### Pseudocode

```text
COMPUTE-PREFIX-FUNCTION(P)
// Compute Ï€ for pattern P (0-based indexing)
    m â† length[P]
    Ï€ â† new array of size m, Ï€[0] â† 0
    k â† 0                           // length of current matched prefix

    for q â† 1 to m âˆ’ 1
        while k > 0 and P[k] â‰  P[q]
            k â† Ï€[kâˆ’1]              // fall back to next possible prefix length

        if P[k] = P[q]
            k â† k + 1

        Ï€[q] â† k

    return Ï€

KMP-MATCHER(T, P)
    n â† length[T]
    m â† length[P]

    if m = 0 return

    Ï€ â† COMPUTE-PREFIX-FUNCTION(P)

    q â† 0                           // number of characters matched

    for i â† 0 to n âˆ’ 1              // scan text from left to right
        while q > 0 and P[q] â‰  T[i]
            q â† Ï€[qâˆ’1]              // mismatch â†’ slide pattern

        if P[q] = T[i]
            q â† q + 1               // match one more character

        if q = m
            print "Pattern occurs with shift" i âˆ’ m + 1
            q â† Ï€[qâˆ’1]              // look for overlapping matches
```

### TypeScript â€“ KMP string matching

```ts
/**
 * Computes the KMP prefix (failure) function Ï€ for the pattern
 * Ï€[q] = longest proper prefix of P[0..q] that is also a suffix
 */
function computePrefixFunction(pattern: string): number[] {
  const m = pattern.length;
  const pi = new Array(m).fill(0);

  let k = 0; // length of previous longest prefix-suffix

  for (let q = 1; q < m; q++) {
    while (k > 0 && pattern[k] !== pattern[q]) {
      k = pi[k - 1]; // fall back
    }

    if (pattern[k] === pattern[q]) {
      k++;
    }

    pi[q] = k;
  }

  return pi;
}

/**
 * Knuth-Morris-Pratt (KMP) string matching
 * Returns all starting positions (0-based) where pattern occurs in text
 */
function kmpStringMatch(text: string, pattern: string): number[] {
  const n = text.length;
  const m = pattern.length;
  const occurrences: number[] = [];

  if (m === 0 || n < m) return occurrences;

  const pi = computePrefixFunction(pattern);

  let q = 0; // current state / matched length

  for (let i = 0; i < n; i++) {
    // Mismatch â†’ slide pattern using prefix info
    while (q > 0 && pattern[q] !== text[i]) {
      q = pi[q - 1];
    }

    // Match one more character
    if (pattern[q] === text[i]) {
      q++;
    }

    // Full match found
    if (q === m) {
      occurrences.push(i - m + 1); // starting position (0-based)
      q = pi[q - 1]; // continue for overlapping matches
    }
  }

  return occurrences;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const text = "ABABDABACDABABCABAB";
const pattern = "ABABCABAB";

console.log("Text:    ", text);
console.log("Pattern: ", pattern);

const positions = kmpStringMatch(text, pattern);

console.log("KMP found pattern at starting positions (0-based):", positions);
// Expected: [10]

console.log("\nAll occurrences:");
positions.forEach((pos) => {
  console.log(`Position ${pos}: ${text.slice(pos, pos + pattern.length)}`);
});

// Another example: overlapping matches
const text2 = "AAAAAAA";
const pattern2 = "AAA";

console.log("\nOverlapping example:");
console.log("Text:   ", text2);
console.log("Pattern:", pattern2);
console.log("Positions:", kmpStringMatch(text2, pattern2));
// Expected: [0, 1, 2, 3, 4]
```

### Important Notes

- Preprocessing time â€” \(\Theta(m)\) â€” very fast.
- Matching time â€” \(\Theta(n)\) â€” strictly linear, no backtracking in the text.
- Handles overlapping matches naturally.
- Space complexity â€” \(\Theta(m)\) for the prefix table.
- The prefix function \(\pi\) encodes all knowledge about self-overlaps in the pattern.
- Often slightly slower than Rabinâ€“Karp in practice due to constants, but has guaranteed linear worst-case time.

### ğŸ“ Key Takeaway

KMP uses the prefix function \(\pi\) to preprocess the pattern in \(\Theta(m)\) time so that, during matching, the text index never moves backward, yielding \(\Theta(n + m)\) worst-case time.

---

## 32.5 Suffix Arrays

This section introduces suffix arrays â€” a powerful and space-efficient data structure for solving many string-matching and string-processing problems. A suffix array is essentially a sorted array of all suffixes of a given text string \(T\).

### Applications

Once built, a suffix array allows fast solutions to problems such as:

- Finding all occurrences of a pattern \(P\) in \(T\).
- Finding the longest repeated substring.
- Finding the longest common substring between two strings.
- Data compression (Burrowsâ€“Wheeler transform).
- Full-text indexing, DNA sequence analysis, etc.

### Core Idea

Given a text \(T\) of length \(n\) (usually ending with a unique sentinel character `$` smaller than any other character):

- The suffixes of \(T\) are
  - \(T[0..nâˆ’1], T[1..nâˆ’1], T[2..nâˆ’1], \dots, T[nâˆ’1..nâˆ’1]\).
- The suffix array `sa` is an array of integers \([0..nâˆ’1]\) such that the suffixes are sorted lexicographically:
  - \(T[sa[0]..nâˆ’1] â‰¤ T[sa[1]..nâˆ’1] â‰¤ â€¦ â‰¤ T[sa[nâˆ’1]..nâˆ’1]\).

Once we have the suffix array, many queries become very fast.

### Advantages over suffix trees

- Much smaller space in practice.
- Simpler construction (especially in real-world implementations).
- Very cache-friendly and fast on modern hardware.

### Basic (naive) construction

- Sort all \(n\) suffixes lexicographically â†’ \(O(n^2 \log n)\) time (due to string comparisons).
- Too slow for very large \(n\), but fine for didactic purposes and small strings.
- Efficient construction algorithms exist in \(O(n)\) or \(O(n \log n)\) time (e.g., DC3, SA-IS).

### Pattern matching using a suffix array

To find all occurrences of pattern \(P\):

1. Perform binary search on the suffix array.
2. Compare \(P\) with \(T[sa[i]..]\) during the search.
3. Find the leftmost and rightmost positions where \(P\) is a prefix.
4. All suffixes between these positions start with \(P\) â†’ report their starting positions `sa[i]`.

Time per query: \(O(m \log n)\) (with \(O(m)\) per comparison).

### LCP array (Longest Common Prefix)

- `LCP[i]` = length of the longest common prefix between suffix `sa[iâˆ’1]` and suffix `sa[i]`.
- With suffix array + LCP, many problems (including pattern matching) can be solved even faster.

### Pseudocode

```text
BUILD-SUFFIX-ARRAY-NAIVE(T)
    // Very slow â€” for illustration only
    n â† length[T]
    let suffixes â† array of n strings: T[i..nâˆ’1] for i = 0 to n âˆ’ 1
    sort suffixes lexicographically
    sa â† array of starting indices in sorted order
    return sa

FIND-PATTERN-IN-SUFFIX-ARRAY(T, P, sa)
    n â† length[T]
    m â† length[P]

    low â† 0
    high â† n âˆ’ 1

    while low â‰¤ high
        mid â† (low + high) / 2
        compare P with T[sa[mid] .. sa[mid] + m âˆ’ 1]

        if P is prefix of T[sa[mid]..]
            // Found one match â€” now find range
            find leftmost and rightmost positions where P matches
            return all sa[i] in that range

        else if P < T[sa[mid]..]
            high â† mid âˆ’ 1
        else
            low â† low + 1

    return no match
```

### TypeScript â€“ suffix array (naive) + pattern matching

```ts
/**
 * Builds a suffix array naively (for small strings only)
 * @param text - input string (should end with unique sentinel if needed)
 * @returns suffix array: indices sorted by suffix lexicographical order
 */
function buildSuffixArrayNaive(text: string): number[] {
  const n = text.length;
  const suffixes: [string, number][] = [];

  // Create all suffixes with their starting index
  for (let i = 0; i < n; i++) {
    suffixes.push([text.slice(i), i]);
  }

  // Sort suffixes lexicographically
  suffixes.sort((a, b) => a[0].localeCompare(b[0]));

  // Extract just the starting indices
  return suffixes.map((s) => s[1]);
}

/**
 * Finds all starting positions of pattern in text using suffix array
 * @param text - the text
 * @param pattern - pattern to find
 * @param sa - precomputed suffix array
 * @returns array of starting positions (0-based)
 */
function findWithSuffixArray(
  text: string,
  pattern: string,
  sa: number[],
): number[] {
  const n = text.length;
  const m = pattern.length;
  const occurrences: number[] = [];

  if (m === 0 || n < m) return occurrences;

  let low = 0;
  let high = n - 1;

  // Binary search for leftmost match
  let left = -1;
  while (low <= high) {
    const mid = Math.floor((low + high) / 2);
    const suffixStart = sa[mid];
    const suffix = text.slice(suffixStart, suffixStart + m);

    if (suffix === pattern) {
      left = mid;
      high = mid - 1; // continue searching left
    } else if (suffix < pattern) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }

  if (left === -1) return occurrences;

  // Find rightmost match
  low = left;
  high = n - 1;
  let right = left;

  while (low <= high) {
    const mid = Math.floor((low + high) / 2);
    const suffixStart = sa[mid];
    const suffix = text.slice(suffixStart, suffixStart + m);

    if (suffix === pattern) {
      right = mid;
      low = mid + 1;
    } else if (suffix < pattern) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }

  // All sa[i] for i = left to right are starting positions
  for (let i = left; i <= right; i++) {
    occurrences.push(sa[i]);
  }

  occurrences.sort((a, b) => a - b); // return in order
  return occurrences;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Example usage
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const text = "banana$"; // $ is sentinel smaller than any char
const pattern = "ana";

console.log("Text:", text);
console.log("Pattern:", pattern);

const sa = buildSuffixArrayNaive(text);
console.log("Suffix array:", sa);

const positions = findWithSuffixArray(text, pattern, sa);
console.log("Occurrences at positions:", positions);
// Expected: [1, 3] (0-based: "ana" at 1 and 3 in "banana$")
```

### Important Notes

- Naive suffix array construction is \(O(n^2 \log n)\) â€” only for small strings.
- Real-world construction algorithms (DC3, SA-IS, etc.) run in \(O(n)\) or \(O(n \log n)\) time.
- Adding the LCP array (longest common prefix) allows faster pattern matching and many other applications.
- Suffix arrays are more space-efficient than suffix trees.
- Widely used in bioinformatics, full-text search, compression (Burrowsâ€“Wheeler transform), etc.

### ğŸ“ Key Takeaway

A suffix array is a sorted array of all suffixes of a text string \(T\). Once built, it supports very efficient exact pattern matching (e.g., via binary search) and many other string-processing tasks.
